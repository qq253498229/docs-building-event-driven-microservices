= 第 16 章 部署事件驱动型微服务

部署事件驱动型微服务富有挑战性。随着组织内微服务数量的增加，标准化部署流程的重要性也随之增加。一个只管理几十个服务的组织可以通过一些定制的部署流程摆脱困境，但任何一个认真投入于事件驱动或其他微服务的组织都必须致力于标准化和优化其部署流程。

[#_16_1_微服务部署的原则]
== 16.1 微服务部署的原则

部署流程应遵循的原则如下。

给予团队部署自主权::
团队应该控制自己的测试和部署流程，并有权自行部署微服务。

实现标准化的部署流程::
服务之间的部署流程应该是一致的。应该用已有的可用的部署流程来创建新的微服务。这通常是通过一个持续集成框架来实现的，稍后将讨论。

提供必要的支持性工具::
部署可能需要团队重置消费者组偏移量、清除状态存储、检查且更新 schema 演化以及删除内部事件流。支持性工具提供了这些功能，以实现部署的进一步自动化并支持团队自治。

考虑事件流再处理的影响::
重新消费输入事件流非常耗时，会导致下游消费到过时的事件。此外，该微服务可能会产生大量输出事件，从而导致下游消费者的高负载。大型的事件流和那些有大量消费者的事件流在处理启动需求时可能会出现不寻常的负载激增。还必须考虑到副作用，特别是那些会对客户造成干扰的副作用（例如，重发多年之前的促销邮件）。

遵守 SLA::
部署可能会干扰其他服务。例如，重建状态存储会产生大量的中断时间，再处理输入事件流会产生大量事件。确保在部署过程中遵守所有 SLA。

最小化依赖服务的变更::
部署操作可能会要求其他服务变更它们的 API 或数据模型，比如当用 REST API 进行交互或引入领域 schema 变更时。这些变更应该尽可能地最小化，因为它们侵犯了其他团队的自主权，这些团队应该只在自身业务需求发生变化时才部署他们的服务。

与下游消费者协商破坏性变更::
在某些情况下，破坏性的 schema 变更可能是不可避免的，需要创建新的事件流并与下游消费者重新协商数据契约。请确保在部署之前完成这些讨论，并为消费者制订迁移计划。

image:image5.png[image,width=47,height=44]
微服务应该是可独立部署的，如果不是则是反模式。如果一个特定的微服务部署通常需要其他微服务同步进行部署，那么这预示着它们的界限上下文没有被很好地定义，应该对其进行重新审视。

[#_16_2_微服务部署的架构组件]
== 16.2 微服务部署的架构组件

微服务部署架构有几个主要组件，每个组件都起着关键作用。下面主要介绍用于构建和部署代码的系统以及微服务所使用的计算资源。

[#_16_2_1_持续集成系统持续交付系统和持续部署系统]
=== 16.2.1 持续集成系统、持续交付系统和持续部署系统

持续集成系统、持续交付系统和持续部署系统允许在将代码变更提交到代码库时构建、测试和部署微服务。这是大规模成功管理和部署微服务必须要付出的微服务税的一部分。这些系统允许微服务所有者决定何时部署其微服务，这对于扩大组织的微服务规模至关重要。

持续集成是将多个贡献者的代码变更自动集成到单个软件项目中的实践。来自代码的变更由管理微服务的团队自行决定进行集成，目的是减少代码变更与部署到生产环境之间的时间间隔。持续集成框架允许在代码合并到主分支时自动执行操作，包括构建操作、单元测试和集成测试操作。其他的持续集成操作包括校验代码风格和执行 schema 演化校验。一个随时准备部署的容器或虚拟机是持续集成管道的最终输出产物。

持续交付是保持代码库可部署的实践。遵循持续交付原则的微服务使用持续集成管道来验证构建是否已准备好进行部署。然而，部署本身并不是自动化的，需要服务所有者一方进行一些人工干预。

持续部署是构建的自动化部署。在一个端到端的持续部署流程中，提交的代码变更通过持续集成管道传播，到达一个可交付状态，然后根据部署配置自动部署到生产环境。这有助于时间紧张的开发迭代，因为提交的变更可以很快进入生产环境。

图 16-1 展示了持续交付和持续部署之间区别的持续集成管道。

.图 16-1：展示持续交付和持续部署之间区别的持续集成管道
image::image543.png[]

image:image5.png[image,width=47,height=44]
持续部署在实践中是很难的。有状态的服务特别有挑战性，因为部署可能需要重建状态存储及再处理事件流，这对依赖服务尤其具有干扰性。

[#_16_2_2_cms和商业硬件]
=== 16.2.2 CMS和商业硬件

CMS 提供了管理、部署和控制容器化应用程序资源的方法（参见 2.9.3 节）。在持续集成过程中构建的容器被存放到容器库中，在那里它等待 CMS 的部署指示。持续集成管道和 CMS 之间的集成对于流水化部署过程至关重要，如第 2 章所述，大部分领先的 CMS 供应商提供了这个功能。

商业硬件通常用于部署事件驱动型微服务，因为它价格便宜、性能可靠，并且支持服务的水平伸缩。可以根据需要在资源池中添加和删除硬件，而恢复故障实例只需要将发生故障的微服务实例重新部署到新硬件。虽然你的微服务实现可能会不同，但事件驱动型微服务不需要操作任何特殊的硬件。如果真的需要操作，可以将专门的资源分配到它们自己的独立池中，这样就可以相应地部署相关的微服务了。这样的例子包括用于缓存目的的内存密集型计算实例，或用于需要大量处理能力的应用程序的处理器密集型计算实例。

[#_16_3_基本的全站式部署模式]
== 16.3 基本的全站式部署模式

基本的全站式部署模式是所有其他模式的基础，本节会概述所涉及的步骤（参见图 16-1）。根据领域的具体要求，你可能在管道中有额外的步骤，但由于篇幅所限我会使这些步骤保持精简。你要依靠自己的判断和领域知识插入任何特定于你的用例的步骤。

1.提交代码。合并最新的代码到主分支，触发持续集成管道。具体细节取决于你的代码库和持续集成管道，但通常是使用可以在代码提交到代码库时执行任意逻辑的提交钩子来实现这一点。

1.执行自动化的单元测试和集成测试。此步骤是持续集成管道的一部分，用于验证提交的代码是否通过了合并所需的所有单元测试和集成测试。集成测试可能需要你启动临时环境并填充数据以执行更复杂的测试。这需要将持续集成管道与 15.6 节中描述的工具集成，以便每个服务都可以建立自己的集成测试环境。

image:image3.png[image,width=40,height=46]
对于任何类型的自动化集成最好有独立的集成测试环境，因为它允许你独立于其他服务运行给定服务的测试。这大大减少了由于共享集成测试环境而产生的多租户问题。

2.运行部署前验证测试。此步骤通过在发布之前验证常见问题来确保微服务能够正确部署。验证分为以下两种类型。

事件流验证::

验证输入事件流是否存在、输出事件流是否存在（或是否可被创建，如果可以自动化创建的话）以及微服务是否有访问它们的合适的读/写权限。

schema 验证::

验证输入 schema 和输出 schema 是否都遵循 schema 演化规则。一种简单的方法是根据约定，将输入 schema 和输出 schema 以及 schema 到事件流的映射包含在特定的目录结构中。管道的此步骤可以简单地接收 schema 并运行比较逻辑，检测任何不兼容的情况。

3.部署。在部署新的微服务之前需要停止当前部署的微服务。这个过程包括两个主要步骤。

a.在部署之前停止实例并执行清除操作。停止微服务实例。执行必要的状态存储重置和/或消费者组重置，并删除所有内部流。如果在部署失败的情况下重建状态代价高昂，那么你可能希望先不管状态、消费者组和内部主题，而是作为新服务部署。这将使你在发生故障时能够快速回滚。

b.部署。执行真正的部署。部署容器化的代码并启动所需数量的微服务实例。等待它们启动并发出准备就绪的信号，然后再进入下一步。如果出现故障，请放弃此步骤并部署之前运行的代码版本。

4.运行部署后验证测试。验证微服务是否正常运行，消费者滞后是否恢复正常，是否没有错误日志以及端点是否按预期工作。

image:image5.png[image,width=47,height=44]
要考虑对所有依赖服务的影响，包括 SLA、中断时间、流处理追赶时间、输出事件负载、新的事件流以及破坏性的 schema 变更。与依赖服务所有者沟通以确保影响是可接受的。

[#_16_4_滚动更新模式]
== 16.4 滚动更新模式

滚动更新模式可用于在更新每个微服务实例时保持服务运行，其前提条件包括以下几项：

* 没有对任何状态存储的破坏性变更；
* 没有对内部微服务拓扑的破坏性变更（特别对于使用轻量级框架的实现）；
* 没有对内部事件 schema 的破坏性变更。

只要满足了前提条件，此部署 schema 就可以很好地适用以下场景：

* 将新的字段添加到输入事件并反映在业务逻辑中；
* 消费新的输入流；
* 修复缺陷但无须重新处理。

image:image5.png[image,width=47,height=44]
无意地改变内部微服务拓扑是人们在尝试使用此部署模式时最容易犯的一个错误。这样做会导致破坏性的变更，将需要完全重置应用程序，而不是滚动更新。

在滚动更新期间，只有 16.3 节中的第 4 步有变化。不再是同一时间停掉所有实例，而是每次只停一个实例。被停掉的实例接着进行更新并重启，这样在部署过程中会混合运行新实例和旧实例。此滚动更新意味着在一小段时间内会同时执行新旧两种逻辑。

image:image3.png[image,width=40,height=46]
智能的实现将运行一个检查版本兼容性的测试，以通知你滚动更新是否有效。手动执行此操作非常容易出错，应该避免。

这种模式的主要优点是可以在不中断处理的情况下更新服务，从而消除中断时间。而主要缺点是它的前提条件限制了其在特定场景中的使用。

[#_16_5_破坏性的schema变更模式]
== 16.5 破坏性的schema变更模式

如 3.1.5 节所述，破坏性的 schema 变更有时候是难以避免的。涉及破坏性 schema 变更的部署必须考虑许多依赖项，包括消费者和生产者的责任、迁移工作的协调以及重新处理中断时间。

部署破坏性的 schema 变更是一个相当简单的技术过程。困难的部分是重新协商 schema 定义、与干系人沟通，以及协调部署和迁移计划。每一个步骤都需要各方之间的明确沟通和清晰的行动时间表。

破坏性的 schema 变更的影响会随着事件类型的不同而变化。破坏性的实体事件 schema 变更会比非实体事件 schema 变更更复杂，因为对消费者物化操作来说实体需要有一致的定义。根据定义，实体也是持久的数据单元，当消费者重新物化实体流时，所有数据单元将被重新消费。实体流必须在新 schema 下被重新创建，包括新的业务逻辑和 schema 定义。

创建新的实体流需要重新处理生产者的源数据，无论来自批处理的是数据源还是它自己的输入事件流。创建新流的逻辑可以构建到原来的生产者服务中，也可以构建一个新的生产者并与原来的服务一起部署。前者将所有逻辑封装在自己的服务中，而后者允许原始生产者不间断地继续其操作，从而减少对下游消费者的影响。这些选项如图 16-2 所示。

.图 16-2：用新 schema 重新创建事件破坏性的 schema 变更的生产者选项
image::image549.png[]

破坏性的 schema 变更通常反映了实体或事件领域的根本性转变。这些不会经常发生，但当它们发生时，变化通常有非常重大的意义，必须更新消费者以反映该领域的业务意义的变化。

另外，对于非实体事件的破坏性 schema 变更可能不需要重新处理事件。这主要是因为许多应用程序无须像处理实体流（可能需要对流进行重新物化）那样定期重新处理非实体事件流。消费者通常可以简单地增加一种新的事件定义，当作一个新的事件流，并修改业务逻辑以处理新旧两种事件。一旦旧事件流中不再有事件产生，消费者就可以简单地删除旧事件流的业务逻辑。

迁移破坏性的 schema 变更有两种主要方案：

* 通过两个事件流达到最终迁移，一个使用旧 schema，另一个使用新 schema；
* 同步迁移到一个新事件流，并删除旧流。

[#_16_5_1_通过两个事件流达到最终迁移]
=== 16.5.1 通过两个事件流达到最终迁移

通过两个事件流达到最终迁移需要生产者同时用新旧格式写事件，然后将它们分别写到对应的流中。旧流会被标记为弃用，而其消费者会在自己的时间周期内迁移到新流。一旦所有消费者都完成迁移，就可以删除旧数据流或将其转移到长期数据存储中。

该策略有以下两种假设。

* 事件可以生成到新旧两个流中。生产者必须有必要的数据来创建新旧两种格式的事件。所生产事件的域已经发生了重大变化，需要进行破坏性的变更，同时又保持了足够的相似性，这使得新旧事件格式的 1∶1 映射仍然有意义。不是所有的破坏性 schema 变更都是这种情况。
* 最终迁移不会导致下游的不一致性。下游服务将继续消费两种不同的定义，但不会产生相应的影响，或者这些影响将是有限的。同样，schema 的破坏性变更表明领域已经发生足够大的改变，因此重新定义对组织来说是必要的。很少会出现这样的情况：破坏性的变更对业务来说是必要的，但对使用事件的消费者来说无关紧要。

image:image5.png[image,width=47,height=44]
最终迁移的一个主要风险是迁移永远得不到结束，并且相似且不同的数据在无限期地使用。此外，在迁移期间创建的新服务可能会在无意中将自己注册为旧流而不是新流的消费者。可使用元数据标记（参见 14.3 节）将流标记为已弃用，并保持较小的迁移窗口。

[#_16_5_2_同步迁移到新事件流]
=== 16.5.2 同步迁移到新事件流

另一种方案是更新生产者以严格使用新格式创建事件，并停止向旧流提供更新。从技术上来说，相比于维护两个事件流，这是一种简单的方案，但它要求数据的生产者和消费者之间进行更密切的沟通。消费者必须更新它们的定义来适配由生产者引入的破坏性的变更。

该策略也有两个假设。

* 事件定义变更足够重大，旧的事件不再可用。实体或事件的领域已经发生非常大的变化，以至于无法同时维护新旧两种格式。
* 必须同步进行迁移以消除下游的不一致性。领域发生了重大变化，服务需要更新以确保能够满足业务需求。否则，下游服务可能会出现严重的不一致。例如，考虑一下，对于一个实体，其成为事件的选择标准发生更改给下游带来的影响有多大。

此部署方案的最大风险是，消费者在迁移到新事件流时可能会失败，但无法像使用最终迁移策略那样优雅地回退到旧的数据源。集成测试（最好使用程序化生成的环境和源数据）可以通过提供一个完全执行迁移过程的测试环境来降低这种风险。你可以在测试环境中创建并注册生产者和消费者，以便在生产环境中执行迁移之前验证迁移过程。

image:image4.png[image,width=40,height=46]
同步迁移在实践中往往很少见，因为这意味着重大的破坏性变更，甚至需要销毁事件以前的领域模型。核心业务实体通常有非常稳定的领域模型，但是当破坏性变更发生时，同步迁移可能就无法避免。

[#_16_6_蓝绿部署模式]
== 16.6 蓝绿部署模式

蓝绿部署的主要目标是在部署新功能时提供零中断时间。该模式主要用于同步的“请求–响应”微服务部署，因为它使得服务在更新时仍然能够继续进行同步请求。图 16-3 展示了该模式的一个例子。

.图 16-3：蓝绿部署模式
image::image559.png[]

在本例中，新微服务（蓝）的完整副本与旧微服务（绿）并行出现。蓝服务有完全隔离的外部数据存储实例、自己的事件流消费者组和自己的远程访问 IP 地址。它会消费输入事件，直到监控指示其已充分赶上绿服务，此时绿实例的流量可以开始重新路由。

服务前面的路由器会执行流量切换。少量流量会被路由到新的蓝实例，这样就能实时验证部署。如果部署过程未检测到任何故障或异常，则可以转移越来越多的流量，直到绿实例不再接收任何流量。

此时，根据应用程序的敏感度和提供快速回退的需要，可以立即关闭绿实例，或将其置于空闲状态，直到在足够的时间内不发生任何事件为止。如果在此冷却期间发生错误，则路由器可以快速将流量重新路由回绿实例。

image:image4.png[image,width=40,height=46]
监控和告警（包括资源使用指标、消费者组滞后度、自动伸缩触发器和系统告警）需要作为颜色切换过程的一部分进行集成。

蓝绿部署对于消费事件流的微服务非常有用。当事件仅由“请求–响应”活动生成时，比如当请求直接转换为事件时，它们也可以很好地工作（参见 13.5 节）。

image:image5.png[image,width=47,height=44]
当微服务响应于输入事件流并向输出流生成事件时，蓝绿部署不起作用。这两个微服务在实体流的情况下将覆盖彼此的结果，在事件流的情况下将创建重复的事件。此时请使用滚动更新模式或基本的全站式部署模式。

[#_16_7_小结]
== 16.7 小结

流水化微服务的部署需要组织支付微服务税并投资必要的部署系统。由于有大量的微服务可能需要管理，最好将部署职责委托给拥有微服务的团队。这些团队需要支持性工具来控制和管理它们的部署。

持续集成管道是部署过程的一个关键部分。它们提供了搭建并执行测试、验证构建以及确保容器化服务完成部署准备的框架。CMS 提供了管理容器在计算集群中的部署、分配资源和提供可伸缩性的方法。

部署微服务的方法有很多，最简单的是完全停止微服务并重新部署最新的代码。但是，这会导致严重的中断时间，并且根据 SLA 的不同，这可能是不合适的。还有其他的部署模式，它们都有自己的优点和缺点。本章讨论的模式绝不是一个全面的列表，而是应该为你确定自己的服务需求提供了良好的起点。
