= 第 4 章 将事件驱动架构与现有系统集成

将组织转变到事件驱动架构需要将现有系统集成到新的生态系统中。你的组织可能有一个或多个单体关系型数据库应用程序。很可能存在不同实现之间的点到点连接。也许组织内已经有在系统之间传输大量数据的类似于事件的机制，比如通过中间的文件存储定期同步数据库镜像。如果是从头建立一个事件驱动型微服务架构，没有历史遗留系统，那真是太棒了！你可以直接跳过本章（尽管应该考虑一下事件驱动型微服务可能并不适合你的新项目）。但是，如果你需要支持现有的遗留系统，请继续阅读。

任何业务领域中都存在通常需要跨多个子领域的实体和事件。例如，一个电子商务零售商将需要提供产品信息、价格、库存和图像到各种界限上下文中。也许付款数据由一个系统收集，但需要在另一个系统中进行验证，然后在第三个系统中分析购买模式。将这些数据放于一个中心化的位置作为新的单一事实来源，当数据可用时，每个系统都可以消费它们。迁移到事件驱动型微服务需要在事件代理中提供必要的业务领域数据，这些数据可以作为事件流使用。这是一个被称为数据解放（data liberation）的过程，涉及从现有系统和包含数据的状态存储中获取数据。

任何系统都可以访问事件流中的数据，无论是事件驱动系统还是其他系统。事件驱动应用程序可以使用流式框架和原生消费者方式来读取事件，但是遗留的应用程序可能由于各种因素（比如技术和性能上的限制）而无法方便地访问这些事件。在这种情况下，需要将事件流中的事件落地到现有的状态存储中。

许多模式和框架可用于获取和落地事件数据。对于每种技术，本章将介绍为什么需要、如何做到以及不同方法间相关的权衡。然后，本章将回顾数据解放和落地如何融入整个组织、它们的影响以及让努力转化为成功的方式。

[#_4_1_什么是数据解放]
== 4.1 什么是数据解放

数据解放是对跨领域数据集的识别并发布到相应事件流中的过程，也是事件驱动架构迁移策略的一部分。跨领域的数据集包括所有存储在某个存储系统中的、其他外部系统所需要的数据。服务间和数据存储间的点到点依赖常常凸显出应该被解放的跨领域数据，如图 4-1 所示，3 个依赖的服务正在直接查询遗留系统。

.图 4-1：点到点依赖，底层服务直接访问数据
image::image56.png[]

数据解放强化了事件驱动架构的两个主要特性：单一事实来源和消除系统间的直接耦合。解放的事件流允许将新的事件驱动型微服务构建成消费者，并在适当的时候迁移现有系统。数据解放之后，响应式事件驱动框架和服务可用于消费和处理数据，下游消费者不再需要直接耦合到源数据系统上。

通过充当单一事实来源，这些事件流标准化了跨组织系统访问数据的方式。系统不再需要直接耦合底层的数据存储和应用程序，而是可以只在事件流的数据契约上进行耦合。数据解放后的工作流如图 4-2 所示。

.图 4-2：数据解放后的工作流
image::image57.png[]

[#_4_1_1_数据解放的折中方案]
=== 4.1.1 数据解放的折中方案

数据集及其解放的事件流必须保持完全同步，尽管由于事件传播的延迟，此要求仅限于最终一致性。解放的事件流必须能物化成原表的一个精确副本，这个特性被广泛应用于事件驱动型微服务（如第 7 章所述）。相反，遗留系统不会从任何事件流中重建数据集，而是通常有自己的备份和恢复机制，并且不从解放的事件流中读取任何数据。

在理想的情况下，所有的状态都要从作为单一事实来源的事件流中创建、管理、维护和恢复。所有共享状态都应该首先被发布到事件代理中，然后物化到所有需要物化这些状态的服务中，包括一开始生产这些数据的服务，如图 4-3 所示。

.图 4-3：在物化之前将事件发布到事件流中
image::image58.png[]

虽然对新的微服务和经过重构的应用程序来说，在事件代理中维护状态的理想可以实现，但要在所有应用程序中这么做并不一定适合且可行。对那些在开始集成“变更数据获取”机制前不太可能重构或更改的服务来说尤其如此。遗留系统对组织来说非常重要又难以重构，最糟糕的情况是原来的代码就是“一个大泥球”（a big ball of mud）。尽管系统很复杂，但其他新系统仍然需要访问它们的内部数据。虽然很希望进行重构，但现实中有许多问题会阻止其进行。

缺乏开发人员支持::

许多遗留系统有极少的开发人员支持，需要低成本的解决方案来生成“解放的数据”。

重构成本::

将已存在的应用程序工作流重新改造成异步事件驱动和同步 MVC（模型–视图–控制器）模式混合的Web 应用程序逻辑是代价非常高的事情，而对复杂的遗留单体系统来说更是如此。

遗留支持风险::

对遗留系统所做的更改可能会产生意想不到的后果，尤其是当因技术债以及与其他系统的点到点连接不明确而导致系统的责任不明确时。

有一种折中的方案。可以使用数据解放的模式从数据存储中提取数据并创建必要的事件流。这是一种单向的事件驱动架构形式，因为遗留系统不会如图 4-3 所示那样从事件流中读回数据。它的根本目标是通过严格控制的事件数据发布过程来保持内部数据集和外部事件流的同步。事件流会与遗留应用程序的内部数据集达到最终一致，如图 4-4 所示。

.图 4-4：在两个服务之间解放并物化状态
image::image59.png[]

[#_4_1_2_将被解放的数据转化成事件]
=== 4.1.2 将被解放的数据转化成事件

与任何其他事件一样，被解放的数据也要遵循第 3 章中介绍的结构化建议。定义良好的事件流的一个特点是，它所包含的事件有一个显式定义的、可演化的兼容 schema。作为 schema 定义的数据契约的一部分，应该确保消费者有基本的数据质量保证。对 schema 的变更只能根据演化规则来进行。

image:image3.png[image,width=40,height=46]
在整个组织中对被解放的事件数据和原始的事件数据采用相同标准的格式。

根据定义，在业务中与业务最相关且常用的数据就是需要被解放的数据。对数据源的数据定义做出更改，比如创建新的字段、更改现有字段或删除其他字段等，可能导致动态变更数据操作传播到下游消费者。如果不能为解放的数据使用显式定义的 schema，那么将迫使下游消费者解决所有不兼容问题。这对提供单一事实来源来说是很困难的，因为下游消费者不应该试图自己解析数据。提供可靠的数据以及最新的schema 并仔细考虑数据随时间的演变，这一点非常重要。

[#_4_2_数据解放模式]
== 4.2 数据解放模式

有 3 种主要的数据解放模式可用于从底层数据存储中提取数据。因为解放数据意味着要形成新的单一事实来源，所以它必须包含数据存储中的全部数据集合。此外，新的插入、更新和删除操作必须保持数据一致。

基于查询::

通过查询底层状态存储提取数据。这可以在任何类型的数据存储中执行。

基于日志::

可以根据记录着底层数据结构变更的追加日志来提取数据。该选项只适用于维护着数据修改日志的选择型数据存储。

基于表::

在这个模式中，首先将数据推送到一个用作输出队列的表中。另一个线程或单独的进程会查询该表，将数据发布到相关的事件流中，然后删除相关实体。这种方法要求数据存储同时支持事务和输出队列机制，通常是将一个单独的表配置为队列使用。

虽然每种模式都是独特的，但这 3 种模式有一个共同点。每种模式都应该以排列好的时间戳顺序生成事件，在输出事件记录头中使用源记录的最新 updated_at 时间。这将以事件的发生时间戳而不是生产者发布事件的时间来生成事件流。这对于数据解放是相当重要的，因为它准确地表示了事件在工作流中的发生时间。基于时间戳的事件交错场景将在第 6 章中进一步讨论。

[#_4_3_数据解放框架]
== 4.3 数据解放框架

解放数据的一种方法是使用专用、集中式的框架将数据提取到事件流中。捕获事件流的集中式框架包括Kafka Connect（专门用于 Kafka 平台）、Apache Gobblin 和 Apache NiFi。每个框架都让你可以对底层数据集执行查询，将结果通过管道传输到输出事件流。这里介绍的每个框架都是可伸缩的，这样就可以添加更多的实例来增加执行“变更数据捕获”（change data capture，CDC）作业的能力。它们支持与Confluent（Apache Kafka）提供的 schema 注册表进行多级别的集成方案，也可以执行自定义操作以支持其他 schema 注册方案。关于“schema 注册”的更多信息，请参见 14.5 节。

并非所有的数据解放过程都需要专用的框架，许多系统更适合直接开发自己的事件流数据生产方案。事实上，这些框架无意中滋生了数据访问的反模式。最常见的反模式之一是将内部数据模型暴露给外部系统，从而进一步增加耦合而不是减少耦合，而后者恰是事件驱动架构应提供的主要优点之一。这一点将在本章接下来的内容中进一步讨论。

[#_4_4_通过查询实施数据解放]
== 4.4 通过查询实施数据解放

基于查询的数据解放涉及查询数据存储并将所选择的结果发布到相关的事件流中。一个使用合适的 API、SQL 或类 SQL 语言的客户端会被用于向数据存储请求特定的数据集。必须能够批量查询数据集以提供事件的历史记录，然后定期更新，以确保数据的更改被发布到输出事件流中。

此模式有几种查询类型。

[#_4_4_1_批量加载]
=== 4.4.1 批量加载

执行批量查询并加载数据集中的所有数据。当需要在每个轮询间隔加载整张表时，以及在进行增量更新之前，都需要执行批量加载。

批量加载成本很高，因为它需要从数据存储中获取整个数据集。对较小的数据集，这可能不是问题，但对大规模的数据集，特别是那些有百万或亿万条记录的数据集来说，则可能很困难。对于查询和处理大规模数据集的情况，我建议研究针对特定数据存储的最佳实践，因为这些最佳实践可能因存储器的实现而不同。

[#_4_4_2_增量时间戳加载]
=== 4.4.2 增量时间戳加载

使用增量时间戳加载，可以查询并加载自上一个查询结果的最大时间戳以来的所有数据。这种方法使用数据集中的一个 updated_at 列或字段来跟踪记录最后一次修改的时间。在每次增量更新时，只查询updated_at 时间戳晚于最后一次处理时间的记录。

[#_4_4_3_自增id加载]
=== 4.4.3 自增ID加载

自增 ID 加载是查询并加载比上一次处理的 ID 值大的所有数据。这需要一个严格有序的整型或长整型字段。在每次增量更新时，只查询 ID 值比上一次处理的 ID 值大的记录。这种方法通常用于查询存储不可变记录的表，比如发件箱表（参见 4.6 节）。

[#_4_4_4_自定义查询]
=== 4.4.4 自定义查询

自定义查询仅受限于客户端查询语言。当客户端只需要较大数据集中的某个数据子集时，或者联结多个表中的数据并对其进行非范式化以避免内部数据模型过度暴露时，通常使用这种方法。例如，用户可以根据特定的字段过滤业务伙伴的数据，然后将每个合作伙伴的数据发送到自己的事件流。

[#_4_4_5_增量更新]
=== 4.4.5 增量更新

任何增量更新的第一步都是确保数据集中的记录有必需的时间戳或自增 ID。必须存在一个字段让查询可用于从要处理的记录中筛选出已被处理的记录。缺失这些字段的数据集需要把它们加上，数据存储需要配置成可以填充必需的 updated_at 时间戳或自增 ID 字段。如果这些字段无法添加到数据集中，那么基于查询的模式就无法使用增量更新。

第二步是确定轮询频率和更新时延。较高的更新频率可以为下游系统带来较低的数据更新时延，但是这会给数据存储造成比较大的总负载开销。考虑请求之间的间隔是否足以完成所有数据的加载也很重要。当旧的查询仍在加载时开始新的查询可能会导致竞争状态，即旧数据会覆盖输出事件流中较新的数据。

一旦选定增量更新字段并确定了更新频率，最后一步就是在增量更新启动之前执行一次批量加载。这次批量加载必须在进一步增量更新之前查询并生成数据集中的所有存量数据。

[#_4_4_6_基于查询更新的优点]
=== 4.4.6 基于查询更新的优点

基于查询的更新具有以下优点。

可定制性::
可以查询任何数据存储，并且所有客户端类型都能用于查询数据。

独立的轮询周期::
可以以较高的频率执行某些特定查询以满足更严格的 SLA，而对于其他开销较大的查询可以降低执行频率以节省资源。

内部数据模型的隔离::
关系型数据库可以通过使用底层数据的视图或物化视图来达到与内部数据模型的隔离。该技术可用来隐藏不应该暴露在数据存储之外的领域模型信息。

image:image5.png[image,width=47,height=44]
请记住，被解放的数据将是单一事实来源。要考虑是否隐藏或忽略了应该被解放的数据，或者是否应该重构源数据模型。这通常发生在数据被从遗留系统里解放出来的过程中，在这些系统里，业务数据和实体数据已经随着时间的推移相互交织在一起。

[#_4_4_7_基于查询更新的缺点]
=== 4.4.7 基于查询更新的缺点

基于查询的更新也有一些缺点。

需要 updated_at 时间戳::
要查询的事件的底层表或命名空间必须有一列包含着它们的 updated_at 时间戳。这对于跟踪最近一次的数据更新时间来做增量更新至关重要。

无法跟踪的硬删除::
硬删除无法在查询结果中体现，所以要跟踪删除只能采用基于标记的软删除，比如 is_deleted 列。

数据集 schema 和输出事件 schema 之间脆弱的依赖关系::
数据集 schema 变更时可能会出现与下游事件 schema 格式规则不兼容的情况。如果数据解放机制的代码与数据存储应用程序的代码是分离的，则崩溃的可能性会越来越大，这在基于查询的系统中很常见。

间歇捕获::
数据只能在间歇性轮询中同步，这样对同一个记录的多次独立变更只能体现为一个事件。

生产资源消耗::
查询使用底层系统资源来执行，这会在生产系统上造成不可接受的时延。使用只读副本可以减轻此问题，但会带来额外的财务成本和系统复杂性。

数据变更导致的查询性能变化::
查询和返回的数据量取决于对底层数据所做的变更。在最坏的情况下，每次都会更改整个数据集。如果某次查询在下一次查询开始时仍未结束，则会出现竞争状态。

[#_4_5_使用变更数据捕获日志解放数据]
== 4.5 使用变更数据捕获日志解放数据

解放数据的另一种模式是使用数据存储底层的变更数据捕获日志（MySQL 中叫二进制日志，PostgreSQL中叫预写式日志）作为信息源。这是一种只追加数据的日志结构，它会详细记录被跟踪的数据集随时间推移所发生的所有变更。这些变更既包括对记录的创建、删除和更新，也包括对数据集及其 schema 的创建、删除和更新。

变更数据捕获的技术选项比基于查询的捕获要少。不是所有的数据存储都有实现一份关于数据变更的持久日志，而在那些支持此能力的数据存储中，也不是全部都有现成的连接器可用于提取数据。这种方法主要适用于选择型的关系型数据库，比如 MySQL 和 PostgreSQL，但是任何具有一套完整的变更日志的数据存储都适用此方法。许多其他现代数据存储有公开事件 API，此 API 可充当物理预写入日志的代理。例如，MongoDB 提供了一个变更流接口，而 Couchbase 通过其内部复制协议提供了复制访问。

数据存储的日志不太可能包括从开始到现在的所有变更，因为这是海量的数据并且通常也没必要保留。在用数据存储的日志进行变更数据捕获处理之前需要获得现有数据的一份快照。这份快照通常涉及一次大数据量的、对性能有影响的表查询，常常被称为自启动（bootstrapping）。必须确保自启动查询结果中的记录和日志中的记录有重叠的部分，这样才不会意外丢失任何数据。

从变更日志捕获事件时必须对进度打上检查点，你所使用的工具可能已经内置此功能。在变更数据捕获机制生成事件失败时，检查点用于恢复到上一次所保存的变更日志索引。这种方法只能提供至少生成一次记录的能力，这种能力往往适合于基于实体的数据解放的特点。因为更新实体数据是幂等的，所以产生额外数据无关紧要。

从变更日志中获取数据有许多可选项。Debezium 是用于关系型数据库的流行选项之一，因为它支持最常见的一些关系型数据库。Debezium 有现成的实现可向 Apache Kafka 和 Apache Pulsar 生成记录。要支持其他事件代理当然也可以，但可能需要自己做一些开发工作。Maxwell 是另一个读取二进制日志的选项，但是它目前只能支持 MySQL 数据库并且只能生成数据到 Apache Kafka。

图 4-5 展示了 MySQL 数据库如何发送其二进制变更日志。一个运行着 Debezium 连接器的 Kafka 连接服务正在消费原始二进制日志。Debezium 会解析数据并将其转换为离散的事件。接下来，事件路由器根据事件的源表将每个事件发送到 Kafka 中的特定事件流。现在，下游消费者就可以通过消费 Kafka 的相关事件流来访问数据库内容了。

.图 4-5：Debezium 从 MySQL 数据库的二进制日志中获取数据并写入 Kafka 事件流中
image::image60.png[]

[#_4_5_1_使用数据存储日志的优点]
=== 4.5.1 使用数据存储日志的优点

使用数据存储日志的优点如下。

删除跟踪::

二进制日志包含记录的硬删除。它们可以转化成删除事件，而无须跟基于查询的更新那样使用软删除。

对数据存储的性能影响最小::

对使用二进制日志和预写入日志的数据存储来说，变更数据捕获的执行不会对数据存储性能有任何影响。对那些使用变更表的数据存储（如 SQL Server）来说，对性能的影响与数据量有关。

低时延更新::

一旦将事件写入二进制日志和预写入日志，就能传播这些更新。比起其他数据解放模式，它有着非常低的时延。

[#_4_5_2_使用数据库日志的缺点]
=== 4.5.2 使用数据库日志的缺点

以下是一些使用数据库日志的缺点。

暴露内部数据模型::

内部数据模型完全暴露在变更日志中。底层数据模型的隔离必须要谨慎而有选择地进行管理，不像基于查询的更新模式可以使用视图来提供隔离。

数据存储外的非范式化::

变更日志只包含事件数据。一些变更数据捕获机制可以从物化视图中提取数据，但是对大多数情况来说，在数据存储外部必须进行数据的非范式化，否则可能会产生高度范式化的事件流，这就需要下游微服务处理外键连接和非范式化。

数据集 schema 和输出事件 schema 之间脆弱的依赖关系::

与基于查询的数据解放过程很相似，基于二进制日志的解放过程存在于数据存储应用程序之外。合法的数据存储变更，比如更改数据集或重新定义字段类型，可能会与事件 schema 的特定演化规则完全不兼容。

[#_4_6_使用发件箱表解放数据]
== 4.6 使用发件箱表解放数据

发件箱表包含对数据存储的内部数据所做的重要修改，每个重要的更新都被存储为单独的一行记录。一旦对标记为需要做变更数据捕获的数据存储表做出插入、更新或删除操作，就会往发件箱表写入一条对应的记录。处于变更数据捕获下的每个表都有自己的发件箱表，或者有一个单独的发件箱表记录所有表的变更（稍后再讨论）。

内部表的更新和发件箱表的更新必须绑定到一个事务中，这样每次更新只有在整个事务成功时才会发生。如果不这样做，可能最终导致很难达成“让事件流作为单一事实来源”的目标，而这是很难检测和修复的。该模式是一种更具侵入性的变更数据捕获方法，因为它需要对数据存储层和应用层进行改动，而这些改动都需要数据存储开发人员的参与。发件箱表模式利用数据存储的持久性为等待发布到外部事件流的事件提供了预写入日志。

内置的变更数据表::

有些数据库，比如 SQL Server，不提供变更数据捕获日志，而是提供变更数据表。这些表通常用于审计数据库操作，并作为内置选项提供。外部服务，比如前面提到的 Kafka Connect 和 Debezium，可以连接到使用变更数据捕获表而不是变更数据捕获日志的数据库，然后使用基于查询的模式提取事件并将其导入事件流。

发件箱表中的记录必须有严格的排序标识符，因为可能对相同的主键在短时间内更新多次。或者，你可以覆盖该主键先前的更新记录，但这需要先找到之前的记录并引入额外的性能开销。这也意味着被覆盖的记录不会被发送到下游。

插入时分配的自增 ID 最适用于确认发布事件的顺序。同时也应该维护一个 created_at 时间戳列，因为它反映了在数据存储中创建记录的事件时间，在发布到事件流期间可以使用它来代替挂钟时间。如第 6章所讨论的，这可以让事件调度器进行精准的安排。

图 4-6 展示了端到端的工作流。数据存储客户端对内部表的更新会跟对发件箱表的更新一起包裹在一个事务中，这样出现任何失败都能保证数据在两个表之间的一致性。同时，一个独立的应用程序线程或进程会持续地轮询发件箱表，并向对应的事件流生成数据。一旦成功生成数据，就删除在发件箱表中的对应记录。如果发生任何失败（无论是数据存储、消费者/生产者还是事件代理本身），发件箱记录仍将保留，不会有丢失数据的风险。该模式提供的是“至少一次”发送的保证。

.图 4-6：发件箱表变更数据捕获方案的端到端工作流
image::image61.png[]

[#_4_6_1_性能考虑]
=== 4.6.1 性能考虑

使用发件箱表会给数据存储及其请求处理应用程序带来额外的负载。对于小负载的小型数据存储，开销可以忽略不计。但是，对于非常大型的数据存储，特别是那些有大量负载和很多表处于捕获状态的数据存储，开销可能会非常高。应根据具体情况评估该方法的成本，并与响应式策略（如解析变更数据捕获日志）的成本进行平衡。

[#_4_6_2_隔离内部数据模型]
=== 4.6.2 隔离内部数据模型

发件箱表不需要与内部表成 1∶1 的映射关系。事实上，发件箱表的一个主要优点就是数据存储客户端可以将内部数据模型与下游消费者隔离。领域的内部数据模型可能使用了大量高度范式化的表，这些表对于关系型数据库是很友好的，但是极度不适用于下游消费者的消费。即使是简单的领域也可能包含多张表，如果暴露为多个单独的事件流，就需要下游消费者进行重新构造才能使用。由于多个下游团队将不得不重建领域模型并处理事件流中的相关数据，因此很快就会让成本变得非常高昂。

image:image5.png[image,width=47,height=44]
暴露内部数据模型给下游消费者是一种反模式。如第 3 章所描述的那样，下游消费者应该只访问按公开的数据契约格式组织的数据。

数据存储客户端可以在插入数据时对数据进行非范式化，以便发件箱表按预期的数据契约做镜像，尽管这样做会牺牲额外的性能和存储空间。另一个选项是维持变更到输出事件流的 1∶1 映射，并使用专用的下游事件处理器对流进行非范式化。我将这个过程称为事件化（eventification），因为它将高度范式化的关系型数据转换为了易于消费的单个事件。它模拟了数据存储客户端应该做的事情，但是在数据存储外部进行的，从而减轻了负载。图 4-7 展示了一个基于用户、位置和雇主信息对用户信息进行非范式化的例子。

.图 4-7：使用私有的用户、位置和雇主事件流对公共的用户事件进行非范式化
image:image62.png[]

在这个例子中，用户有一个外键指向他们所居住的国家、州/省份和城市，同时还有一个外键指向他们当前的雇主。用户事件的下游消费者想要每个用户的所有信息全都在一个事件中是很合理的，而不是被迫将每个事件流都物化为状态存储，然后用关系型工具进行非范式化。从发件箱表里获取原始的、范式化的事件到它们自己的事件流中，但将这些流保持在与组织其他部分无关的私有命名空间内（参见 14.3 节），以保护内部数据模型。

用户事件化的过程是对用户实体进行非范式化并去掉所有内部数据模型结构的过程。此过程需要维护用户、位置和雇主的物化表，以便任何更新都能重新执行联结逻辑并为所有受影响的用户发出更新事件。最终的事件会被发送到组织的公共命名空间以供所有下游消费者消费。

在向事件驱动型微服务发展的组织中，内部数据模型与外部消费者的隔离程度往往会成为争论的焦点。隔离内部数据模型对于确保服务的解耦和独立性，以及确保面对新的业务需求时只需改变本服务而无须更改上游内部数据模型是至关重要的。

[#_4_6_3_确保schema兼容性]
=== 4.6.3 确保schema兼容性

schema 序列化以及校验也可以构建到捕获工作流中。它可以在事件被写入发件箱表之前或之后执行。成功则意味着事件可以在工作流中继续，而失败意味着可能需要人工干预以确定根本原因并避免数据丢失。

提交事务到发件箱表之前的序列化提供了最强的数据一致性保证。序列化的失败会导致事务失败并回滚所有对内部表的修改，从而确保发件箱表和内部表保持同步。这个过程如图 4-8 所示。校验成功则会进行事件序列化并准备发布到事件流。该方法的主要优点是内部状态和输出事件流之间的数据不一致性显著降低。事件流数据被视为“一等公民”，发布正确的数据与保持一致的内部状态同等重要。

.图 4-8：写入发件箱表之前序列化变更数据
image::image63.png[]

写入发件箱表之前的序列化支持对所有事务都使用同一个发件箱表的选项。这个格式很简单，因为内容主要是带有目标输出事件流映射的序列化数据，如图 4-9 所示。

.图 4-9：存储了经过校验和序列化的事件的单一输出表（注意用于路由的 output_stream 列）
image::image64.png[]

在发布之前执行序列化的一个缺点是，由于序列化开销，性能可能会受到影响。这对于轻负载业务可能无关紧要，但对于较重负载的业务有显著的影响。你需要确保性能需求得到满足。

或者，也可以在事件被写入发件箱表后执行序列化，如图 4-10 所示。

.图 4-10：作为发布过程的一部分，在写入发件箱表之后对变更数据执行序列化
image::image65.png[]

使用这种策略，通常有独立的发件箱，每个领域模型对应一个发件箱，映射到相应输出事件流的公开schema。发布器进程从发件箱读取未序列化的事件并在将它们发布到输出事件流之前尝试用对应的schema 进行序列化。图 4-11 展示了一个有多个发件箱表的例子，其中一个对应用户实体，另一个对应账户实体。

.图 4-11：多个发件箱表（注意数据没有被序列化，这意味着它可能与输出事件流的 schema 不兼容）
image::image66.png[]

序列化失败则表示事件的数据不符合其定义的 schema，因此无法发布。这就是写操作之后进行序列化比较难维护的地方，因为提交的事务已将不兼容的数据推送到了发件箱表，并且无法保证事务可以回退。

实际上，通常会在发件箱中出现大量不可序列化的事件。很可能需要人工干预来尝试挽救一些数据，但解决这个问题既耗时又困难，甚至需要停机以避免其他问题。事实上，在人工干预期间，有些事件可能是兼容的且已发布到事件流中，这会导致输出流中的事件顺序可能不正确。

image:image3.png[image,width=40,height=46]
事实发生前的序列化提供了比事实发生后的序列化更强大的兼容性保证，并防止了违反其数据契约的事件的传播。折中之处在于，如果序列化失败，那么此实现将阻止业务流程完成，因为必须回滚事务。

写入之前进行校验和序列化可以确保数据被视为“一等公民”，并保证输出事件流中的事件最终与源数据存储中的数据一致，同时还可以保持源内部数据模型的隔离。这是变更数据捕获方案能提供的最强保证。

pass:[1. 用发件箱表生成事件的优点]

用发件箱表生成事件有许多显著的优点。

多语言支持::
任何拥有事务能力的客户端或框架都支持此方法。

事实发生之前的 schema 操作::
在将数据插入发件箱表之前可以进行 schema 校验和序列化。

隔离内部数据模型::
数据存储应用程序的开发人员可以选择要将哪些字段写入发件箱表，保持内部字段隔离。

非范式化::
数据可以根据需要在写入发件箱表之前进行非范式化。

pass:[2. 用发件箱表生成事件的缺点]

使用发件箱表生成事件也有一些缺点。

需要变更应用程序代码::
必须变更应用程序代码以启用该模式，这需要来自应用程序维护者的开发和测试资源。

影响业务处理性能::
对业务工作流的性能影响可能非常大，尤其是通过序列化校验 schema 时。失败的事务也会阻止业务操作继续进行。

影响数据存储性能::
对数据存储的性能影响可能非常大，尤其是从发件箱表写入、读取和删除大量记录时。

image:image4.png[image,width=40,height=46]
性能影响必须与其他成本保持平衡。例如，一些组织只是简单地解析变更数据捕获日志来发出事件，而将事后清理工作留给下游团队来处理。这会给下游团队带来一系列开销，既包括处理和标准化事件的计算成本，也包括解决不兼容 schema 和处理与内部数据模型强耦合的影响等形式的人力成本。生产方节省的成本与消费方处理这些问题所产生的成本相比往往相形见绌。

[#_4_6_4_使用触发器捕获变更数据]
=== 4.6.4 使用触发器捕获变更数据

与前文讨论过的审计、二进制日志和预写入日志模式相比，触发器出现得更早。许多较旧的关系型数据库使用触发器作为生成审计表的方法。顾名思义，触发器被设置为在特定条件下自动发生。如果失败，那么导致触发器执行的命令也将失败，从而确保更新的原子性。

可以使用 AFTER 触发器捕获行级别的变更到审计表中。例如，执行任何 INSERT、UPDATE 和 DELETE 命令之后，触发器都会向变更数据表中写入对应的一行数据。这样可以确保对特定表所做的变更得到相应的跟踪。

考虑图 4-12 所示的例子。其正在更新插入用户数据到用户表，同时有一个触发器在它们发生时捕获事件。请注意，触发器还捕获了插入发生的时间以及事件发布者进程要使用的自增序列 ID。

.图 4-12：使用触发器捕获对用户表的变更
image::image67.png[]

在触发器执行期间通常无法用事件 schema 校验变更数据。一个主要问题是它可能根本不受触发器支持，因为触发器在数据库内部执行，而且许多触发器仅限于它们可以支持的语言形式。虽然 PostgreSQL 支持C、Python 和 Perl 语言，可用来写自定义的函数以执行 schema 校验，但是许多其他的数据库并没有提供多语言的支持。最后，即使支持触发器，它的代价可能也过于高昂。每个触发器都是独立触发的，需要大量开销来存储必要的数据、schema 和校验逻辑，这对许多系统负载来说成本太高。

图 4-13 延伸了上一个例子。对变更数据执行事后的校验和序列化，将成功校验的数据生成到输出事件流中。不成功的数据需要根据业务需求进行错误处理，但更可能的是需要人工干预。

.图 4-13：事后校验并生成事件到输出事件流
image::image68.png[]

变更数据捕获表 schema 是内部表 schema 和输出事件流 schema 之间的桥梁。三者之间的兼容性对于确保将数据生成到输出事件流至关重要。由于输出 schema 校验通常不会在触发器执行期间执行，因此最好保持变更数据表的格式与输出事件 schema 同步。

image:image3.png[image,width=40,height=46]
在测试阶段，将输出事件 schema 的格式与变更数据表进行比较，可以在生产部署之前暴露不兼容性问题。

由此看来，触发器在许多遗留系统中发挥着重大作用。根据定义，遗留系统倾向于使用旧技术；触发器已经存在了很长时间，可以很好地提供必要的变更数据捕获机制。如果访问和负载模式是定义良好且稳定的，就可以准确评估添加触发的影响。最后，虽然 schema 校验不太可能发生在触发过程中，但是由于系统的遗留特性，schema 也不太可能发生变化。只有当 schema 需要频繁更改时，事后校验才是个问题。

image:image5.png[image,width=47,height=44]
如果可以使用更现代的功能来生成或访问变更数据，请尽量避免使用触发器。不应低估基于触发器的解决方案所需的性能和管理开销，尤其是当涉及数十张甚至上百张表和数据模型时。

pass:[1. 使用触发器的优点]

使用触发器的优点如下。

大部分数据库支持::
触发器存在于大部分关系型数据库中。

对小数据集来说开销低::
对于小数据集，维护和配置都相当容易。

自定义逻辑::
触发器代码可以自定义为只暴露部分特定字段。它可以为暴露给下游消费者的数据提供一定程度的隔离。

pass:[2. 使用触发器的缺点]
使用触发器的缺点如下。

性能开销::
触发器与数据库表上的操作内联执行，并且可能消耗大量的处理资源。根据服务的性能要求和SLA，这种方法可能会导致不可承受的负载。

变更管理的复杂性::
对应用程序代码和数据集定义的变更需要修改对应的触发器。系统维护人员可能会忽略对底层触发器的必要修改，从而导致数据解放的结果与内部数据集不一致。应进行全面测试以确保触发器工作流按预期运行。

糟糕的可伸缩性::
触发器数量应随着要被捕获的数据集数量线性伸缩。这要排除业务逻辑中可能已经存在的所有其他触发器，比如用于增强表之间依赖关系的触发器。

事后结构化::
对输出事件的结构化只能发生在已经将记录写到发件箱表之后。这可能会导致在发件箱中有无法发布的事件。

image:image3.png[image,width=40,height=46]
某些数据库允许触发器在执行期间用可校验数据和输出事件 schema 兼容性的语言来执行（例如，PostgreSQL 可以用 Python 来执行）。这会增加复杂性和开销，但会显著降低下游schema 不兼容的风险。

[#_4_7_对处于捕获的数据集做数据定义变更]
== 4.7 对处于捕获的数据集做数据定义变更

在数据解放框架中集成数据定义变更是很困难的。数据迁移对许多关系型数据库应用程序来说是常见操作，并且数据捕获过程需要支持它们。关系型数据库的数据定义变更包括对列的添加、删除和重命名，更改列的类型，以及添加或删除默认值。虽然所有这些数据集变更操作都是合法的，但它们可能会对解放事件流数据造成问题。

image:image4.png[image,width=40,height=46]
数据定义是对数据集的正式描述。例如，关系型数据库中的一张表是用数据定义语言（data definition language，DDL）来定义的。结果表、列、名称、类型和索引都是其数据定义的一部分。

如果要求完全的 schema 演化兼容性，就不能删除处于捕获中的数据集中没有默认值的非空列，因为正在使用之前所定义的 schema 的消费者期望有这个字段的值。消费者将无法回退使用任何默认值，因为在契约定义阶段没有指定，所以它们最终将处于一种不明确的状态。如果不兼容的变更是绝对必要的，并且违反数据契约无法避免，那么数据的生产者和消费者必须就新的数据契约达成一致。

image:image5.png[image,width=47,height=44]
对处于捕获中的数据集的合法变更可能对解放事件 schema 来说是非法的。这种不兼容性将导致破坏性的 schema 变更，从而影响事件流的所有下游消费者。

捕获 DDL 变更依赖于用于捕获变更数据的集成模式。由于 DDL 变更会对数据的下游消费者产生重大影响，因此确定捕获模式能在事前或事后检测到 DDL 变更非常重要。例如，查询模式和 CDC 日志模式只能在事后（也就是说，变更已经应用到数据集上了）检测到 DDL 变更。相反，变更数据表模式与源系统的开发周期集成在一起，因此可以在生产发布前对数据集所做的变更进行校验。

[#_4_7_1_为查询和cdc日志模式处理事后数据定义变更]
=== 4.7.1 为查询和CDC日志模式处理事后数据定义变更

对于查询模式，可以在查询时获取 schema，并推断事件 schema。新事件 schema 可以与输出事件流schema 进行比较，使用 schema 兼容性规则来允许或禁止事件数据的发布。许多查询连接器使用这种schema 生成机制，比如 Kafka Connect 框架。

对于 CDC 日志模式，数据定义更新通常被记录到 CDC 日志中的专有部分。需要从日志中提取这些变更，并推断其对应数据集的 schema。一旦 schema 生成，就可以对下游事件 schema 进行校验。但是，对该功能的支持是有限的。目前，Debezium 连接器只支持 MySQL 的数据定义变更。

[#_4_7_2_为变更数据表捕获模式处理数据定义变更]
=== 4.7.2 为变更数据表捕获模式处理数据定义变更

变更数据表是输出事件流 schema 和内部状态 schema 之间的桥梁。应用程序校验代码或数据库触发器函数中的任何不兼容都将阻止数据写入变更数据表，并将错误发送回栈。对变更数据捕获表所做的变更需要有 schema 演化，根据 schema 兼容性规则与输出事件流进行兼容。这种先写入变更数据表再写入事件流的两阶段处理，将大大减少无意的变更进入生产的机会。

[#_4_8_将事件数据落地到数据存储]
== 4.8 将事件数据落地到数据存储

从事件流中落地数据包括消费事件数据并写入数据存储。这可以通过集中式框架或独立的微服务来实现。实体事件、键控事件或无键事件等任何类型的事件都可以落地到数据存储。

事件落地对于集成非事件驱动应用程序和事件流非常有用。落地进程从事件代理读取事件流并插入数据到特定的数据存储。它跟踪自己的消费偏移量，并在输入到来时写入事件数据，完全独立于非事件驱动应用程序。

事件落地的典型应用是替代遗留系统之间直接的点到点耦合。一旦将源系统的数据解放到事件流中，用很少的改动就能把它落地到目标系统。落地进程是在外部无形地对目标系统进行操作。

需要执行基于批处理的大数据分析团队也经常将数据落地。他们通常将数据放入 Hadoop 分布式文件系统来实现这一点，Hadoop 分布式文件系统提供了大数据分析工具。

在像 Kafka Connect 这样的通用平台上，可以使用简单的配置指定落地器，并在共享基础设施上运行它们。独立的微服务落地器提供了另一种解决方案。开发人员可以在微服务平台上创建、运行和独立管理它们。

[#_4_9_数据落地和获取对业务的影响]
== 4.9 数据落地和获取对业务的影响

集中式框架对解放数据的处理有较低的开销。这种框架可能会在一个团队内大规模使用，然后反过来支持组织内其他团队的数据解放需求。想要集成的团队只需关注连接器的配置和设计，而无须考虑任何操作职责。这种方法在较大的组织中最有效，在这类组织内数据存储在跨多个团队的多个数据存储里，因为它允许快速开始数据解放，而不需要每个团队都构建自己的解决方案。

集中式框架有两个主要的陷阱。首先，数据获取/落地的责任现在由多个团队分担。操作集中式框架的团队负责框架和每个连接器实例的稳定性、可伸缩性和健康度。同时，操作处于被捕获状态的系统的团队是独立的，可以做出改变连接器性能和稳定性的决策，比如添加和删除字段，或者更改会影响通过连接器传输的数据量的逻辑。这在两个团队之间引入了直接的依赖。这些更改可能会破坏连接器，但只有连接器管理团队才能检测到，从而导致线性扩展的、跨团队的依赖性。随着变更数量的增加，这可能会成为一个难以管理的负担。

第二个问题更加普遍，尤其是在一个只部分采用事件驱动原则的组织中。系统可能过于依赖框架和连接器来完成事件驱动工作。一旦数据从内部状态存储中解放出来并发布到事件流中，组织就会对完成微服务改造而沾沾自喜。团队会过度依赖连接器框架来获取和落地数据，并选择不将其应用程序重构为原生的事件驱动应用程序。在这种情况下，他们宁愿只在必要时请求新的源并落地数据，而让整个底层应用程序完全对事件无感知。

image:image5.png[image,width=47,height=44]
CDC 工具并不是迁移到事件驱动架构的最终目的地，而是主要用于帮助启动这个过程。作为数据通信层，事件代理的真正价值在于提供一个与实现层解耦的健壮、可靠和真实的事件数据源，只有好的数据质量和可靠性才有好的代理。

通过正确理解变更数据捕获框架的作用，这两个问题都可以得到缓解。也许与直觉相反，但尽可能减少CDC 框架的使用并让团队实现自己的变更数据捕获（比如发件箱模式）是很重要的，尽管这可能需要额外的前期工作。团队变得可以专注负责发布他们的系统事件，消除了跨团队依赖性和基于脆弱连接器的CDC。这样可以最大限度地减少 CDC 框架团队需要做的工作，并让他们专注于支持真正需要他们的产品。

减少对 CDC 框架的依赖也会传播“事件优先”的态度。不要将事件流视为在单体系统之间清洗数据的方式，而是将每个系统视为事件的直接发布者和消费者，加入事件驱动生态系统中。通过成为 EDM 生态系统中的积极参与者，你将开始考虑系统何时以及如何生成事件，并会考虑发布到外部的数据，而不仅仅是发布到本系统的数据。这是向成功实现 EDM 的文化转变的一个重要部分。

对于资源有限和只进行维护的产品，集中化的获取和落地连接器系统有巨大的好处。对于其他产品，尤其是那些更复杂、具有重要事件流需求且正在积极开发的产品，连接器的维护和支持是不可持续的。在这些情况下，最好根据需要安排时间重构代码库，以使应用程序成为真正的原生事件驱动应用程序。

最后，仔细考虑每种 CDC 策略的利弊。这常常会成为组织内部讨论和争论的一个领域，因为团队会试图找出他们在将事件作为唯一事实来源的过程中的新职责和边界。迁移到事件驱动架构需要对数据通信层进行投资，而这一层的可用性永远要和它里面的数据质量一样好。组织中的每个人都必须转变思维，考虑其解放的数据对组织其他部分的影响，并对其生成的事件的 schema、数据模型、顺序、时延和正确性提出明确的 SLA。

[#_4_10_小结]
== 4.10 小结

数据解放是向提供成熟和可访问的数据通信层迈出的重要一步。遗留系统通常包含大部分核心业务领域模型，这些模型存储在某种集中式沟通结构中。需要将数据从这些遗留系统中解放出来，以使组织的其他领域能够组成新的、解耦的产品和服务。

有许多框架、工具和策略可用于从其实现的数据存储中提取和转换数据。每种方法都有自己的优点、缺点和权衡。你的实际情况将影响你的选择，或者你可能会发现必须创建自己的机制和处理过程。

数据解放的目标是为组织中重要的数据提供一个干净且一致的单一事实来源。对数据的访问与数据的生产和存储分离，消除了实现沟通结构承担双重任务的需要。这个简单的行为缩小了从遗留系统的众多实现中访问重要领域数据的边界，并直接促进了新产品和新服务的开发。

数据解放有一系列的策略。在这一系列策略中的一端是与源系统小心集成，在源系统中，事件在写入数据存储时会被发送到事件代理。有些系统甚至可以先生成事件流，然后再为了自身需求而消费它，从而进一步加强了事件流作为单一事实来源的作用。生产者认识到了它作为一个好的数据生产公民的角色，并会采取适当的保护措施来防止无意的破坏性变更。生产者会寻求与消费者合作，以确保高质量、定义良好的数据流，最大限度地减少破坏性变更，并确保对系统的变更与他们正在生成的事件的 schema 兼容。

在另一端，你会发现那种响应性很强的策略。实现中的源数据所有者对事件代理中的数据生成几乎不可知。它们完全依赖于框架，要么直接从内部数据集中提取数据，要么解析“变更数据捕获”日志。扰乱下游消费者的破坏性 schema 很常见，从源实现中暴露内部数据模型也是如此。从长远来看，这种模型是不可持续的，因为它忽略了数据所有者确保干净、一致地生成领域事件的责任。

组织的文化决定了数据解放计划在走向事件驱动架构方面的成功程度。数据所有者必须认真对待生成干净可靠的事件流的要求，并明白把数据捕获机制作为解放事件数据的最终目的是不够的。
