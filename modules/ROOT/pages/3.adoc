= 第 3 章 通信和数据契约

> 通信的根本问题是在一个点上精确或近似地再现在另一个点选择的消息。 ——Claude Shannon

信息论之父 Claude Shannon 指出，通信的最大障碍是，确保信息的消费者能够准确地再现生产者的信息，从而使信息的内容和含义都得到正确的传达。生产者和消费者必须对信息有一个共同的理解；否则，它可能会被误解，通信将是不完整的。在事件驱动生态系统中，事件就是消息，且是通信的基本单元。一个事件应该尽可能准确地描述发生了什么以及为什么会发生。这是事实的一个状态，当把系统中的所有其他事件结合在一起时，就能提供事实发生的完整历史。

[#_3_1_事件驱动数据契约]
== 3.1 事件驱动数据契约

要传递的数据的格式和创建数据的逻辑构成了数据契约。事件数据的生产者和消费者都遵循此契约。它赋予了事件意义和形式，使其超出产生事件的上下文，并将数据的可用性扩展到消费者应用程序。

定义良好的数据契约有两个组成部分。第一部分是数据定义，或者说是会产生什么（例如，字段、类型和各种数据结构）。第二部分是触发逻辑，或者说是为什么会产生（例如，触发事件创建的特定业务逻辑）。随着业务需求的发展，可以对数据定义和触发逻辑进行更改。

变更数据定义时必须特别注意，以避免删除或改变正在被下游消费者使用的字段。类似地，改变触发逻辑时也必须很小心。更改数据定义比更改触发逻辑要常见得多，因为改变后者往往会破坏原有事件定义的含义。

[#_3_1_1_使用显式schema作为契约]
=== 3.1.1 使用显式schema作为契约

实施数据契约并提供一致性的最佳方法是为每个事件都定义一个schema。生产者定义了一个显式的schema来详细描述数据定义和触发逻辑，所有相同类型的事件都遵循此格式。这样，生产者提供了一种机制来向所有潜在的消费者传递其事件格式。相反，消费者可以根据结构化的数据明确地构建它们的微服务业务逻辑。

image:image5.png[image,width=47,height=44]
如果缺乏显式预定义schema，那么任何在生产者和消费者之间基于事件的通信的实现，都将不可避免地依赖于隐式schema。隐式数据契约是脆弱的，容易受到变化的影响，而且这种变化往往是不可控的，这会给下游消费者带来很多不必要的困难。

消费者必须能够提取其业务流程所需的数据，而在没有对“可用数据”做出定义的情况下，他无法做到这一点。消费者通常必须依靠部落知识1和团队间的交流来解决数据问题，这一过程随着事件流和团队数量的增加会变得不可持续。要求每个消费者独立解释数据也存在很大的风险，因为消费者对数据的解释可能与同行不同，从而导致对单一事实来源的看法不一致。

> 1部落知识（tribal knowledge）是指仅被公司里的一部分人（而非所有人）了解的信息。这种信息没有任何书面记录。——编者注

image:image5.png[image,width=47,height=44]
构建公共库以对所有服务使用的事件给出解释听上去是一个很诱人的方案，但这会给多语言格式、事件演化和独立的发布周期带来问题。最好避免让多个服务做重复的事情来保证隐式数据定义的一致性。

生产者在使用隐式 schema时也会陷入困难的境地。即使是出于好意，生产者也可能不会注意到（或者他们的单元测试没有发现）他们已经更改了事件数据定义。如果没有显式检查其服务的事件格式，则直到其下游消费者出现问题时才能发现错误。显式schema 为消费者和生产者提供了安全性和稳定性。

[#_3_1_2_schema定义的注释]
=== 3.1.2 schema定义的注释

schema定义中对注释和元数据的支持对于传递事件的含义至关重要。围绕事件的生产和消费的知识应该尽可能接近事件定义。schema注释有助于消除对数据含义的模糊性，并减少消费者误解的机会。注释主要在以下两方面特别有价值。

* 指定事件的触发逻辑。这通常写在schema 文件的首部，并且应该清楚地说明生成事件的原因。
* 给出结构化 schema中特定字段的上下文和清晰解释。例如，日期时间字段的注释可以说明格式是UTC、ISO还是 Unix 时间。

[#_3_1_3_全能的schema演化]
=== 3.1.3 全能的schema演化

schema 格式必须支持一整套 schema 演化规则。schema演化使生产者能够更新其服务的输出格式，同时允许消费者继续不间断地消费事件。业务变更可能需要添加新字段、弃用旧字段或扩展字段范围。schema演化框架确保这些变更可以安全地发生，并且生产者和消费者可以相互独立地更新。

如果没有 schema演化的支持，那么服务更新可能会有很高的代价。生产者和消费者被迫密切协调，以前兼容的旧数据可能不再与当前系统兼容。当生产者更改数据schema时，期望消费者更新他们的服务是不合理的。事实上，微服务的核心价值主张是，除非在特殊情况下，否则它们应该独立于其他服务的发布周期。

一组显式的 schema演化规则可以让消费者和生产者按照自己的时间安排更新应用程序。这些规则称为兼容性类型。

向前兼容性::
允许像读取旧 schema 生成的数据一样读取新 schema生成的数据。在事件驱动架构中，这是一个特别有用的演化需求，因为最常见的系统变更模式是从生产者用新的schema 更新其数据定义并生成数据开始的。消费者只需要在访问新字段时更新其schema 副本和代码。

向后兼容性::
允许像读取新 schema 生成的数据一样读取旧 schema生成的数据。这使得数据消费者可以用新的schema读取旧的数据。向后兼容性对于以下场景来说特别有用。
* 消费者正在等待上游团队发布新特性。如果新的 schema已被定义，那么消费者就可以在生产者发布之前发布自己的更新。
* schema编码的数据来自部署在硬件设备上的产品应用，比如手机应用程序会上报用户指标。可以对新版本产品的 schema 格式做出更新，同时保持对之前版本的兼容性。
* 消费者应用程序可能需要重新处理事件流中的数据，而这些数据是用旧的 schema版本生成的。schema演化确保了消费者可以将旧的版本转换成现在使用的版本。如果没有向后兼容性，那么消费者将只能读取最新格式的消息。

完全兼容性::
将向前兼容性和向后兼容性结合起来，这是最强的保证，并且应该尽可能地使用这种方式。你可以在将来随时放宽兼容性要求，但收紧它们往往要困难得多。

[#_3_1_4_有代码生成器支持]
=== 3.1.4 有代码生成器支持

代码生成器用于将一个事件 schema转化成指定编程语言的类定义或等价的结构。这个类定义被生产者用于创建和填充新的事件对象。编译器或序列化程序（依赖于实现）要求生产者遵从数据类型并填充所有在原始schema中指定的非空字段。然后，生产者创建的对象会被转换成它们的序列化格式并发送到事件代理中，如图3-1 所示。

.图 3-1：使用代码生成器的生产者事件发布流程
image::image52.png[]

事件数据的消费者会维护自己的 schema版本，这通常是跟生产者一致的版本，但也可能是较旧或较新的schema，其取决于schema 演化规则。如果是完全兼容的情况，那么服务可以使用任意 schema版本来生成其定义。消费者读取事件并用编码该事件的 schema版本对其反序列化。事件格式可以跟消息存储在一起（这在大规模使用时成本很高），或者存储在schema 注册器里按需获取（参见 14.5 节）。一旦反序列化成原始的格式，就能将事件转化成消费者所支持的 schema 版本。演化规则会在此时发挥作用，在缺失字段上填充默认值，并将未用到的字段完全去除。最后，数据被转换成一个基于 schema 生成的类的对象。此时，消费者的业务逻辑可以开始执行其操作了。这个过程如图 3-2 所示。

.图 3-2：使用代码生成器的消费者消费及转换事件的流程。注意，消费者将生产者创建的 V2 schema事件转换成了消费者使用的 V1 schema 事件
image::image53.png[]

有代码生成器支持的最大好处是能够根据所选语言的类定义编写应用程序。如果使用的是编译型语言，那么代码生成器将提供编译器检查，以确保没有错误地处理事件类型或忘记填充任何指定的非空数据字段。除非遵循 schema 格式，否则不能编译代码，因此如果不遵循 schema 数据定义，你将无法发布应用程序。编译型语言和非编译型语言都受益于用一个类实现来编写代码。当你试图将错误的类型传递给构造函数或 setter 时，现代 IDE 会提醒你，而如果你使用一个通用的格式，比如键/值映射对象，则不会收到任何提醒。减少错误处理数据的风险可以在整个生态系统中提供更加一致的数据质量。

[#_3_1_5_破坏性的schema变更]
=== 3.1.5 破坏性的schema变更

有时候，必须以某种方式变更 schema 定义，但这可能导致破坏性的演化。发生这种情况的原因有很多，包括不断变化的业务需求改变了原始域的模型、对原始域的不适当的范围界定，以及定义 schema 时的人为错误。虽然生产服务可以很容易地改变以适应新的 schema，但是对下游消费者的影响是不同的，需要加以考虑。

image:image3.png[image,width=40,height=46]
在处理破坏性的 schema 变更时，最重要的是尽早和下游消费者进行清晰的沟通。确保所有迁移计划得到每个相关人员的理解和认可，不会让任何人措手不及。

虽然要求生产者和消费者之间密切协调有些过于烦琐，但数据契约的重新协商和域模型的更改需要所有人支持。除了重新协商 schema，还需要执行一些额外的步骤来适配新 schema 和从中创建的新事件流。破坏性的 schema 变更对无限期存在的实体往往有相当大的影响，但对在给定时间段后过期的事件影响较小。

pass:[1. 让实体适配破坏性的 schema 变更]

对实体 schema 的破坏性变更是相当罕见的，因为这种情况通常需要重新定义原始域模型，这样就不能简单地扩展当前模型。新实体将在新 schema 下创建，而以前的实体将在旧 schema 下生成。数据定义的这种差异给你留下了两个选项：

* 同时处理新旧两种 schema；
* 以新 schema 格式重新创建所有实体（通过迁移，或者通过代码重新创建它们）。

第一个选项对于生产者来说更简单，但它将不同实体定义的解析责任推给了消费者。这与 尽量避免消费者单独解析数据这一目标相矛盾，并增加了误解、服务之间的处理不一致以及维护系统的复杂性大大提高的风险。

image:image5.png[image,width=47,height=44]
事实上，在解决 schema 定义分歧时，相对于生产者来说，消费者永远处于较劣势的地位。把责任推给消费者是不好的做法。

第二个选项对于生产者来说比较困难，但可以确保对新旧业务实体进行一致的重新定义。实际上，生产者必须重新处理用于生成旧实体的源数据，并且在新的格式下用新的业务逻辑来重新创建实体。这种方法会迫使组织作为一个整体来解决定义这些实体的含义以及生产者和消费者应该如何理解和使用它们的问题。

image:image3.png[image,width=40,height=46]
将旧 schema 下的旧实体留在原来的事件流中，因为你可能需要用它们来做重新处理的验证和论证调查。使用新 schema 生成新的实体到新的流中。

pass:[2. 让事件适配破坏性的 schema 变更]

当你并入破坏性的变更时，非实体事件往往比较容易处理。最简单的选项是创建一个新的事件流并在该事件流中生成新事件。必须通知到旧事件流的消费者，以便他们可以将自己注册为新事件流的消费者。每个消费服务还必须解释两个事件定义之间在业务逻辑上的差异。

image:image5.png[image,width=47,height=4]
不要在一个事件流中混合不同的事件类型，尤其是在演化上不兼容的事件类型。事件流的创建开销很低，逻辑分离对于确保消费者在处理事件时拥有完整的信息和明确的定义非常重要。

考虑到旧的事件流不再有新的事件产生，每个消费服务的消费者最终都将消费完所有事件。随着时间的推移，流的事件保留期到达后最终将导致流的完全清除，此时所有消费者都可以注销自己，并且可以删除事件流。

[#_3_2_选择事件格式]
== 3.2 选择事件格式

虽然有许多选项可用于格式化和序列化事件数据，但数据契约最好使用定义明确的格式（如 Avro、Thrift 或 Protobuf）来实现。一些最流行的事件代理框架支持序列化和反序列化用这些格式编码的事件。例如，Apache Kafka 和 Apache Pulsar 支持 JSON、Protobuf 和 Avro schema 格式。支持这两种事件代理的机制是 schema 注册，14.5 节会对此进行更详细的介绍。虽然对这些序列化选项的详细评估和比较超出了本书的范围，但是有许多在线资源可以帮助你在这些选项中做出决策。

你可能倾向于选择一个更灵活的选项，也就是使用简单的键/值对表示纯文本的事件格式，它提供了一些结构，但是没有提供显式的 schema 或 schema 演化框架。然而，这种方法要谨慎使用，因为它会损害微服务通过强大的数据契约保持彼此隔离的能力，而导致需要更多的团队间沟通。

image:image3.png[image,width=40,height=46]
非结构化的纯文本事件通常会成为生产者和消费者的负担，尤其是用例和数据会随着时间的推移而发生变化。如前所述，建议选择支持受控的 schema 演化的强定义、显式的 schema 格式，比如Apache Avro 或 Protobuf。不推荐 JSON，因为它不提供完全兼容的 schema 演化。

[#_3_3_设计事件]
== 3.3 设计事件

在创建事件定义时，有许多最佳实践可以遵循，也有一些需要避免的反模式。请记住，随着由事件驱动型微服务支持的架构数量不断增加，事件定义的数量也在不断增加。设计良好的事件将最大限度地减少消费者和生产者在其他方面的重复痛点。尽管如此，下面将要讲述的这些都不是硬性规定。你可以在自认为合适的情况下突破它们，但我建议，在这么做之前你应考虑周全并仔细权衡利弊。

[#_3_3_1_只讲述事实]
=== 3.3.1 只讲述事实

优秀的事件定义不仅仅是一条表明某件事情发生的消息，而是对在该事件期间发生的所有事情的完整描述。用业务术语来说，这就是在接收输入数据并应用业务逻辑时生成的结果数据。这个输出事件必须被视为唯一的事实来源，并且必须被记录为一个不可变的事实，以供下游消费者消费。关于实际发生的事情，它是完全且权威的信息来源，消费者不需要查阅任何其他数据源就知道发生了这样的事件。

[#_3_3_2_每个流都使用单一事件定义]
=== 3.3.2 每个流都使用单一事件定义

事件流应该包含表示单一逻辑事件的事件。不建议在一个事件流中混合不同类型的事件，因为这样做会混淆事件的定义和流代表的含义。在这种场景中，由于可能会动态地添加新 schema，因此很难对正在生成的事件进行 schema 验证。尽管在某些特殊情况下，你可能希望忽略这一原则，但是在系统架构中生产和消费的绝大多数事件流应该有严格、单一的定义。

[#_3_3_3_使用最窄的数据类型]
=== 3.3.3 使用最窄的数据类型

为事件数据选用最窄的类型。这可以让你依赖代码生成器、语言类型检查（如果支持的话）和序列化单元测试来检查数据边界。听起来很简单，但在很多情况下，当你使用不正确的类型时，歧义就会慢慢出现。以下是一些很容易避免的实际例子。

使用字符串类型来存储数值::

这需要消费者解析字符串并将其转换成数值，并且通常会出现像 GPS 坐标那样的奇怪数值。这很容易出错，特别是在发送空值或空字符串时。

将整型作为布尔型使用::

虽然 0 和 1 可以分别用来表示假和真，但是 2 表示什么呢？-1 又表示什么呢？

将字符串类型作为枚举型使用::

这对于生产者来说是个问题，因为生产者必须确保发布的值与接收的伪枚举列表匹配。这不可避免地会出现输入错误和不正确的值。对这个字段感兴趣的消费者需要知道可能的值的范围，这将需要与生产团队沟通，除非在 schema 注释中指定了这个范围。这两种做法都是隐式定义，因为生产者无法监控字符串中值的范围的任何更改。整个方法都很糟糕。

生产者通常会避免使用枚举，因为其害怕在创建一个新的枚举值时，这个值在消费者的 schema 中不存在。但是，消费者有责任考虑它无法识别的枚举值，并判断是否应该使用默认值进行处理，或者只是抛出一个致命异常并停止处理，直到有人能够确定需要做什么。Protobuf 和 Avro 都有处理未知枚举值的优雅方法，如果选择了其中一种事件格式，则应使用其对应方法。

[#_3_3_4_保持事件的单一用途]
=== 3.3.4 保持事件的单一用途

一种常见的反模式是向事件定义中添加 type 字段，其中不同的 type 值表示事件的特定子功能。这通常是针对“相似但不同”的数据执行的操作，常常是由于实现者错误地将事件标识为单一用途而造成的结果。虽然看起来像是一种节省时间或简化数据访问模式的措施，但用 type 参数重载事件往往并非明智之举。

这种方法会带来一些问题。每个 type 参数值通常都具有截然不同的业务含义，即使其技术上的表示与其他类型值几乎相同也是如此。这些含义可能随着时间的推移而改变，事件所涵盖的范围也会逐渐扩大。其中一些类型可能需要添加新参数来跟踪该类型的特定信息，其他类型则需要单独的参数。你最终可能会碰 到这样的情况：一些非常不同的事件全都遵循相同的事件 schema，这就很难讲清楚事件的真实含义是什么了。

这种复杂性不仅会影响必须维护和填充这些事件的开发人员，还会影响数据的消费者，他们需要对发布的 数据和发布的原因有一致的理解。如果数据契约发生变更，则他们希望能将自己与这些变更隔离开来。添加额外的字段类型需要他们过滤出关心的数据。消费者可能无法完全理解类型的各种含义，从而导致不正确的消费和逻辑错误的代码。对于每个消费者，必须执行额外操作以丢弃与该消费者无关的事件。

image:image5.png[image,width=47,height=44]
需要特别注意的是，添加 type 字段并不能降低或消除所生成数据中固有的底层复杂性。事实上，这种复杂性只不过从具有不同 schema 的多个不同事件流转移到了将所有 schema 合并到一个事件流中的联合体。可以说，这实际上增加了复杂性。schema 的未来演化变得更加困难，维护产生事件的代码也变得更加困难。

记住数据契约定义的原则。事件应该与单个业务操作相关，而不是记录大量数据的通用事件。如果你发觉自己需要一个具有各种 type 参数的泛型事件，那么这通常是一个信号，表明你没有很好地定义问题空间和界限上下文。

示例：重载事件定义::

想象一个简单的网站，用户可以在上面读书或看电影。当用户第一次使用此网站时，比如打开书或播放电影，后端服务会将此作为事件（名为 ProductEngagement）发布到事件流中。这个事件的数据结构可能如下所示。

----
TypeEnum: Book,
Movie ActionEnum: Click

ProductEngagement {
    productId: Long,
    productType: TypeEnum,
    actionType: ActionEnum
}
----

现在想象一下，一个新的业务需求来了：你需要跟踪谁在观看电影之前看了电影预告片。图书是没有预览的，虽然布尔值适用于观看电影的场景，但它必须是可以为空的，以适合读书的场景。

----
ProductEngagement {
    productId: Long,
    productType: TypeEnum,
    actionType: ActionEnum,
    //只应用于productType=Movie
    watchedPreview: {null, Boolean}
}
----

在这一点上，watchedPreview 与 Book 没有任何关系，但是无论如何它都被添加到了事件定义中，因为我们已经用这种方式捕获了产品的使用情况。如果你觉得对下游消费者特别有帮助，那么可以在 schema 中添加注释，告诉它们该字段只与 type=Movie 相关。

另一个新的业务需求出现了：你需要跟踪在图书中放置了书签的用户，并记录它在哪一页。同样，由于只定义了一个表示产品使用的事件结构，因此你的行为被限制为添加一个新的动作实体（Bookmark）和添加一个可为空的字段 pageId。

----
TypeEnum: Book,Movie
ActionEnum: Click, Bookmark

ProductEngagement {
    productId: Long,
    productType: TypeEnum,
    actionType: ActionEnum,
    //只应用于productType=Movie
    watchedPreview: {null, Boolean},
    //只应用于productType=Book, actionType=Bookmark
    pageId: {null, Int}
}
----

正如你现在所看到的，业务需求中的一些更改可以极大地使试图服务于多种业务用途的 schema 复杂化。这增加了数据生产者和消费者的复杂性，因为他们都必须检查数据逻辑的有效性。要收集和表示的数据总是复杂的，但是通过遵循单一责任原则，可以将 schema 分解得更易于管理。下面来看看根据单一职责拆分每个 schema 会是什么样。

----
MovieClick {
    movieId: Long,
    watchedPreview: Boolean
}

BookClick {
    bookId: Long
}

BookBookmark {
    bookId: Long,
    pageId: Int
}
----

productType 和 actionType 枚举现在已经不存在了，schema 也相应地扁平了。现在有 3 个事件定义而不是 1 个，虽然 schema 定义数量增加了，但是每个 schema 的内部复杂性大大降低了。按照每个流一个事件定义的建议，你将看到为每个事件类型创建一个新的流。事件定义不会随时间推移而变化，触发逻辑不会改变，消费者可以在单一用途事件定义的稳定性中获得安全。

这个例子说明并不是原来的事件定义创建者犯了错误。事实上，当时业务关心的是任一产品的使用情况而不是具体产品的使用情况，所以原来的定义是很合理的。一旦业务需求更改为包括跟踪特定于电影的事件，服务的所有者就需要重新评估事件定义是否仍是服务于单一的用途，或者它现在是否覆盖了多个用途。由于业务对事件细节的要求较低，因此很明显，虽然事件可以服务于多个用途，但很快就会变得复杂且笨拙。

image:image5.png[image,width=47,height=44]
避免在事件中添加 type 字段使事件的含义过多。这会给事件格式的演化和维护带来很大的困难。

花点儿时间考虑 schema 是如何演变的。确定所生成数据的主要业务用途、范围、域，以及是否正将其构建为单一用途。验证 schema 是否准确地反映了业务关注点，特别是对于覆盖广泛业务功能职责范围的系统。业务范围和技术实现有可能是不一致的。最后，不断发展的业务需求会要求你重新审视事件定义并可能更改它们，而不仅仅是对单个 schema 的增量定义。如果发生了足够多的业务变更，则可能需要对事件进行拆分和重新定义。

[#_3_3_5_最小化事件]
=== 3.3.5 最小化事件

当事件很小、定义明确且易于处理时，它们会工作得很好。不过，有时候确实会出现“大”事件。一般来说，这些较大的事件代表了大量的上下文信息。也许它们包含许多与给定事件相关的数据点，是对发生的事情的一个非常大规模的测量。

当你看到一个产生非常大的事件的设计时，有几点注意事项。确保数据与事件直接相关。有些数据可能只是“以防万一”地被添加到事件中，但对下游消费者没有任何实际用处。如果发现所有的事件数据确实是直接相关的，那么退一步看看你的问题空间。你的微服务是否需要访问这些数据？你可能需要评估界限上下文，以查看服务是否正在执行合理数量的工作。也许可以通过将附加功能拆分为单独的服务来缩小服务范围。

但是这种情况并不总是可以避免的，有些事件处理器会生成非常大的输出文件（可能是一个大图像），这些文件太大了，以至于无法放入事件流的单条消息中。在这些场景中，可以使用指向实际数据的指针，但要谨慎。这种方法以多个事实来源和内容可变的形式增加了风险，因为不可变的日志无法保证能保存这个系统之外的数据。

[#_3_3_6_让潜在的消费者参与事件设计]
=== 3.3.6 让潜在的消费者参与事件设计

在设计新事件时，让这些数据的所有潜在消费者都参与进来是很重要的。与生产者相比，消费者将更好地理解自己的需求和预期的业务功能，并可能有助于澄清需求。消费者也将更好地了解即将到来的数据。一次联席会议或讨论可以解决两个系统之间有关数据契约的任何问题。

[#_3_3_7_避免将事件作为信号量或信号]
=== 3.3.7 避免将事件作为信号量或信号

避免将事件作为信号量或信号来使用。这些事件只是表明某些事情已经发生，而不是单一事实来源的结果。

考虑一个非常简单的例子。系统输出一个事件，表明某一作业的工作已经完成。虽然事件本身表明工作已完成，但实际的工作结果不包括在事件中。这意味着要正确消费此事件，必须找到已完成工作的实际位置。一旦一段数据有两个事实来源，就会出现一致性问题。

[#_3_4_小结]
== 3.4 小结

异步的事件驱动架构严重依赖于事件质量。高质量的事件用可演化的 schema 显式定义、具有定义良好的触发逻辑，并包括带有注释和文档的完整 schema 定义。对于生产者来说，隐式 schema 虽然更容易实现和维护，但其将大部分解释工作交给了消费者。由于事件数据丢失和意外更改，它们也更容易发生意想不到的故障。显式 schema 是广泛采用事件驱动架构的一个重要组成部分，特别是随着组织的发展，部落知识在组织范围内的传播已变得不可能。

事件定义应该是狭义的，并密切聚焦于事件的领域。事件应该表示一个特定的业务情况，并包含适当的数据字段来记录所发生的事情。这些事件构成了关于业务操作的官方叙述，并且可以由其他微服务根据自己的需要进行消费。

schema 演化是显式 schema 的一个非常重要的方面，因为它允许事件域模型有一个受控的变更机制。领域模型的演化是很常见的，特别是那些随着新的业务需求的出现和组织的扩张而进行的演化。schema 演化允许生产者和消费者将自己与对其操作不重要的更改隔离开来，同时允许那些关心更改的服务相应地更新自己。

在某些情况下，schema 演化是不可能的，破坏性的变更一定会发生。生产者和消费者干系人必须沟通这些变化背后的原因，并一起重新定义未来的领域模型。迁移旧事件可能是必要的，也可能没必要。
