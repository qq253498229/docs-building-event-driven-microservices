= 第 12 章 使用轻量级框架的微服务

轻量级框架提供了与重量级框架相似的功能，但是是通过大量使用事件代理和 CMS 的方式来实现的。与重量级框架不同，轻量级框架没有额外的专用资源集群来管理框架专用的资源。水平伸缩、状态管理和故障恢复是由事件代理和 CMS 提供的。跟所有 BPC 微服务一样，应用程序会作为单独的微服务被部署。并行度由消费者组的成员情况和分区所有权情况决定。当新的应用程序实例加入和离开消费者组时，分区将重新分配（包括协同分区的分配）。

[#_12_1_优点和局限性]
== 12.1 优点和局限性

轻量级框架提供的流处理特性可与重量级框架相媲美，而且在许多情况下超过了后者。将流物化到表，加上简单的开箱即用的联结功能，使得处理流以及其中的相关数据变得相当简单。虽然表的物化功能不是轻量级框架所特有的，但是它的易用性预示着轻量级框架可以解决复杂的有状态的问题。

通过使用内部事件流，轻量级模型依赖事件代理来提供数据局部性和协同分区的机制。事件代理还通过使用变更日志来充当微服务内部状态的持久存储机制，如 7.2 节所述。通过使用 CMS，你可以像部署任何其他的事件驱动应用程序一样部署轻量级微服务。你可以简单地通过添加和移除实例来调整应用程序的并行度，使用 CMS 来提供伸缩和故障管理机制。图 12-1 展示了基础的轻量级模型，包括用户实例间通信的内部事件流。

.图 12-1：轻量级框架模型，展示了传递再分区数据的内部事件流的用法
image::image329.png[]

轻量级框架的限制主要在于当前可使用的选项，这将在本章后面介绍。

[#_12_2_轻量级处理]
== 12.2 轻量级处理

轻量级框架反映了重量级框架的处理方法。单个实例根据拓扑处理事件，事件代理提供了实例间的通信层，以实现超越单个实例的可伸缩性。

相同键的数据必须落到对应的处理实例以进行任何基于键的操作，比如 join 或 groupByKey 等操作（紧接着会执行 reduce 或 aggregation 操作）。这些洗牌操作涉及通过内部事件流来发送事件（而不是直接的实例到实例的方式），给定键的每个事件都会被发送到相同的分区（参见 5.3 节）。

轻量级框架利用事件代理提供通信路径，这说明了轻量级应用程序与事件代理的深度集成。重量级框架则明显不同，它要求在节点之间直接进行大量协调。当与 CMS 提供的应用程序管理方案相结合时，轻量级框架比重量级框架更符合现代微服务所需的应用程序部署和管理的特征。

[#_12_3_处理状态和使用变更日志]
== 12.3 处理状态和使用变更日志

轻量级框架的默认操作模式是使用事件代理中存储的变更日志所支持的内部状态。使用内部状态使得每个微服务可以通过部署配置来控制它所获取的资源。

image:image3.png[image,width=40,height=46]
由于每个轻量级应用程序都是完全独立的，因此一个应用程序可以要求运行在具有高性能的本地磁盘的实例上，而另一个应用程序可以要求运行在具有非常大容量（尽管速度可能慢得多）的硬盘驱动器的实例上。

轻量级框架也可以插入不同的存储引擎，这使得你可以使用具有不同模型和查询引擎的外部状态存储。这样就能收获轻量级框架功能的所有好处，同时还能支持图形数据库和文档存储等选项。

与重量级框架的检查点模型不同，使用内部状态存储的轻量级框架利用事件代理来存储其变更日志。这些变更日志提供了伸缩和故障恢复所需要的持久性。

[#_12_4_伸缩和故障恢复]
== 12.4 伸缩和故障恢复

伸缩微服务和故障恢复实际上是同一个过程。如果想增加一个应用程序实例（由于想要对长期运行的进程进行扩容，或是由于进行故障恢复），就需要正确地分配分区以及与之关联的状态。类似地，如果想移除一个应用程序实例（有意地或由于故障），则需要将分区和状态重新分配给另一个活跃的实例，以避免处理被中断。

轻量级框架模型的一个主要优点是应用程序可以在执行过程中动态地伸缩。尽管由于消费者组的再平衡和对变更日志中状态的重新物化，处理过程中可能会有延迟，但更改并行度无须再重启应用程序。图 12-2展示了扩容一个应用程序的过程。在继续执行工作之前，要对分配的输入分区进行再平衡（包括所有的内部流），并且要从变更日志中恢复状态。

.图 12-2：扩容一个轻量级微服务
image::image330.png[]

下面来看看伸缩轻量级应用程序时主要考虑的因素。

[#_12_4_1_事件洗牌]
=== 12.4.1 事件洗牌

在使用轻量级框架的微服务中，事件洗牌是很简单的，就是将事件再分区到内部事件流中以供下游消费。这个内部事件流隔离了创建洗牌事件的上游实例和消费它们的下游实例，它扮演着类似于重量级框架中洗牌服务的角色以执行动态伸缩。动态伸缩只需要给消费者再分配内部事件流，而不用管生产者的情况。

[#_12_4_2_状态分配]
=== 12.4.2 状态分配

在发生伸缩时，分配了新状态的实例必须先从变更日志中加载数据，之后才能处理新的事件。这类似于重量级解决方案中从持久性存储器里加载检查点的过程。所有事件流分区（包括输入流和内部流）的算子状态（映射为 <partitionId,offset>）存储在每个应用程序的消费者组中。键控状态（<key,state> 对）存储在应用程序的每个状态存储的变更日志中。

当从变更日志中重新加载数据时，应用程序实例必须在处理任何新事件之前优先消费和加载所有内部有状态的数据。这是状态恢复阶段，在状态完全恢复之前对事件的任何处理都有造成不确定性结果的风险。一旦应用程序拓扑中的每个状态存储都完全恢复状态，就可以安全地恢复消费输入流和内部流的事件。

[#_12_4_3_状态复制和热副本]
=== 12.4.3 状态复制和热副本

如 7.3.4 节所述，热副本是从变更日志中物化的状态存储的副本。当提供数据服务的主实例出现故障时，它提供了切换到备用实例的能力，同时也可以对有状态的应用程序进行柔性缩容。当终止一个实例及再平衡消费者组时，可以将原分区分配给热副本所在实例，利用热副本的状态继续处理事件而不发生中断。热副本使得你在伸缩和故障期间可保持高可用性，但代价是要使用额外的磁盘和处理器。

类似地，可以使用热副本无缝地扩容实例，而不必经历由于新节点上的状态重新物化而导致的处理暂停。轻量级框架当前面临的一个问题是，扩容实例当前通常遵循的工作流如下。

. 启动一个新实例。
. 加入消费者组并再平衡分区所有权。
. 当从变更日志物化状态时暂停操作（可能会花费一些时间）。
. 恢复处理。

一种方法是先在新实例上填充状态副本，等待它处理完变更日志，然后执行再平衡为其分配分区所有权。这种模式减少了由于物化变更日志流而导致的中断，并且只需要来自事件代理的额外带宽就可以做到这一点。Kafka Streams 目前正在开发这个功能。

[#_12_5_选择一个轻量级框架]
== 12.5 选择一个轻量级框架

目前，有两个主要的适用于轻量级框架模型的方案，它们都需要使用 Apache Kafka 事件代理。这两个框架在其高级 API 中提供永久保留的物化流，解锁了诸如主键联结和外键联结之类的选项。这些联结模式使得你可以处理关系型数据，而不必物化到外部状态存储，因此减少了编写基于联结的应用程序的认知开销。

[#_12_5_1_apache_kafka_streams]
=== 12.5.1 Apache Kafka Streams

Kafka Streams 是一个嵌入到某个应用程序中的功能强大的流处理库，其中输入事件和输出事件存储在Kafka 集群中。它结合了编写和发布标准 JVM 应用程序的简单性，以及利用与 Kafka 集群深度集成的流处理框架的强大性。

[#_12_5_2_apache_samza嵌入模式]
=== 12.5.2 Apache Samza：嵌入模式

Samza 提供了许多与 Kafka Streams 一样的特性，虽然在与独立部署相关的某些特性方面它还有些滞后。Samza 早于 Kafka Streams，它最初的部署模型基于使用重量级集群。直到最近，Samza 才发布了一个嵌入模式，这个模式与 Kafka Streams 的应用程序编写、部署和生命周期管理模式相似。

就像所有其他的 Java 库一样，Samza 的嵌入模式使你可以在单个应用程序中嵌入它的功能。这个部署模式不需要依赖于专门的重量级集群，而是依赖于前面讨论过的轻量级框架模型。默认情况下，Samza 依赖于使用 Apache ZooKeeper 来进行跨单独实例的协调，但是可以将其修改为使用其他的协调机制（如Kubernetes）。

image:image5.png[image,width=47,height=44]
Apache Samza 的嵌入模式可能不会提供它在集群模式下所拥有的所有功能。

轻量级框架不如重量级框架或用于 BPC 模式的消费者/生产者库那样普遍。轻量级框架确实极度依赖与事件代理的集成，这限制了它们在其他事件代理技术上的可移植性。轻量级框架领域还相当年轻，但随着EDM 领域的成熟，它肯定会不断发展壮大。

[#_12_6_语言和语法]
== 12.6 语言和语法

Kafka Streams 和 Samza 都是基于 Java 的，这使得它们只能用于基于 JVM 的语言。其高级 API 是一种 MapReduce 语法形式，这与重量级框架语言一样。那些在函数式编程或第 11 章中讨论的任何重量级框架方面有经验的人，对这两种框架中的任何一种都会感到很熟悉。

Apache Samza 支持开箱即用的类 SQL 语言，尽管这个功能目前仅限于简单的无状态查询。虽然 Kafka Streams 的企业赞助商 Confluent 在自己的社区许可证下提供了 KSQL，但是 Kafka Streams 并没有支持自己的 SQL。与重量级解决方案非常类似，这些 SQL 解决方案是底层流库之上的封装，可能无法提供流库能直接提供的全部功能和特性。

[#_12_7_流表表联结增强模式]
== 12.7 流–表–表联结：增强模式

假设你现在在一家大型广告公司（就是 11.12 节提到的那家公司）工作，但你是会话窗口的下游消费 者。先来快速回顾一下，窗口化的会话事件格式如表 12-1 所示。

表 12-1：广告–会话流的键/值定义

|===
|键 |值
|WindowKey<Window windowId,String userId>
|Action[] sequentialUserActions
|===

在这里，一个动作包含以下内容。

----
Action {
    Long eventTime;
    Long advertisementId;
    Enum action; //枚举项为Click和View
}
----

你们团队的目标是消费 Advertisement-Sessions 流并执行以下操作。

* 1. 对于每一个广告观看动作，确定紧接着是否有点击动作。对每个“观看–点击”对求和，并输出为转化事件，格式如表 12-2 所示。

.表 12-2：广告–转化流的键/值定义
|===
|键 |值
|Long advertisementId
|Long conversionSum
|===

* 2. 按 advertisementId 对所有广告转化事件进行分组，并将它们的值加总。
* 3. 按 advertisementId 将转化事件与物化的广告实体流联结，这样你的服务就可以根据哪个客户拥有该广告而进行计费，如表 12-3 所示。

.表 12-3：广告实体流的键/值定义
|===
|键 |值
|Long advertisementId
|Advertisement<String name,String address, ...>
|===

下面是 Kafka Streams 的一些源码示例，你可以通过这些源代码了解此操作。其中，KStream 是对流的高级抽象，而 KTable 是对表的高级抽象，由物化广告实体流时所产生。

----
KStream<WindowKey,Actions> userSessions = ...

//将一个用户会话转换成1到N 的转化事件，以AdvertisementId为键
KTable<AdvertisementId,Long> conversions = userSessions
    .transform(...) //将用户会话转换成转化事件
    .groupByKey()
    .aggregate(...) //创建聚合KTable

//物化广告实体
KTable<AdvertisementId,Advertisement> advertisements = ...

//这些表在拓扑里的联结操作中是自动协同分区的
conversions
    .join(advertisements, joinFunc) //参见下面阶段4里的详细介绍
    .to("AdvertisementEngagements")
----

代码表示的拓扑如图 12-3 所示。

.图 12-3：对广告参与情况进行统计的处理拓扑
image::image331.png[]

阶段 1a 和 2a::

Advertisements 实体流会包含较多事件，单个实例难以处理，所以需要多个处理实例来并行执行代码。在这个例子中，最大并行级别初始化为 3，因为这是 Advertisements 实体流的分区数。在非高峰时段可以使用一个或两个实例来处理，但是在用户非常活跃的时段，应用程序的处理会落后于事件的产生。

幸运的是，Advertisements 实体流可以通过内部流重新划分为 12 个匹配的分区。事件被简单地消费并被再分区到有 12 个分区的内部流中。广告实体基于 advertisementId 与来自阶段 1b 和 2b 的转化事件进行协同定位（置于相同编号的分区）。

阶段 1b 和 2b::

从 Advertisement-Sessions 事件流中消费事件，然后产生转化事件，进行制表并发出事件（键=Long advertisementId，值 =Long conversionSum）。请注意，对于一个给定的会话事件，可能会产生多个转化事件，每个 advertisementId 的每对“观看–点击”事件对应一个转化事件。这些事件基于advertisementId 与来自阶段 1a 和 2a 的广告实体事件进行协同定位（置于相同编号的分区）。

阶段 3::

Advertisement-Conversions 事件现在必须聚合成如表 12-4 所示的物化表格式，因为业务想要永久保留每个 Advertisements 实体的参与情况。聚合是对给定的 advertisementId 的所有值的简单加总。

表 12-4：总的广告–转化流的键/值定义

|===
|*Long advertisementId*
|*Long conversionSum*
|AdKey1|402
|AdKey2|600
|AdKey3|38
|===

因此，由聚合算子处理的 (AdKey1,15) 的新的 Advertisement-Conversions 事件将使 AdKey1 的内部状态存储值从 402 增加到 417。

阶段 4::

该拓扑的最后阶段是联结阶段 3 创建的物化的 Total-Advertisement-Conversions 表与再分区的Advertisements 实体流。通过在阶段 2a 和 2b 对输入流的协同分区（这确保了所有以 advertisementId为键的数据都是它的处理实例的本地数据），你已经建立起了联结的基础。Advertisements 流中的实体物化到它们自己的本地分区的状态存储上，并随后与 Total-Advertisement-Conversions 进行联结。

要使用联结函数来指定想要的联结结果，这非常像使用 SQL 中的 select 语句来选择应用程序需要的字段。针对该场景的 Java 联结函数如下所示。

----
public EnrichedAd joinFunction (Long sum, Advertisement ad) {
    if (sum != null || ad != null)
        return new EnrichedAd(sum, ad.name, ad.type);
    else
        //当出现一个输入是null时，可能预示着是一个删除事件，
        //此时返回一个null（逻辑删除）
        return null;
}
----

前面的 joinFunction 假设输入可能是 null，这预示着上游删除了该事件。相应地，你需要确保代码输出一个对应的“逻辑删除”给下游消费者。幸运的是，大多数框架（轻量级和重量级）区分了内联结、左联结、右联结、外联结和外键联结，并会执行一些底层操作以避免通过联结函数传播逻辑删除。但是，出于讲解的目的，考虑微服务拓扑中逻辑删除事件的影响是很重要的。

该 Kafka Streams 拓扑和 joinFunction 等价于 SQL 中的选择表达式。

----
SELECT adConversionSumTable.sum, adTable.name, adTable.type
FROM adConversionSumTable FULL OUTER JOIN adTable
ON adConversionSumTable.id = adTable.id
----

在这个例子中，Enriched-Advertising-Engagements 输出事件流的物化视图如表 12-5 所示。

表 12-5：**Enriched-Advertising-Engagements**流的键/值定义

|===
|*AdvertisementId*（键）
|*Enriched advertisements*（值）
|AdKey1
|sum=402, name="Josh's Gerbils", type="Pets"
|AdKey2
|sum=600, name="David's Ducks", type="Pets"
|AdKey3
|sum=38, name="Andrew's Anvils", type="Metalworking"
|AdKey4
|sum=10, name="Gary's Grahams", type="Food"
|AdKey5
|sum=10, name=null, type=null
|===

这个样例表展示了阶段 3 联结了 Advertising 实体数据的聚合结果。AdKey4 和 AdKey5 展示了完全外联结的结果，其中 AdKey4 还没有转化发生，AdKey5 则没有可用的广告实体数据。

image:image3.png[image,width=40,height=46]
请检查你的框架文档以确定可以使用哪种类型的联结。Kafka Streams 支持外键表–表联结，这对于处理关系型事件数据是相当有用的。

[#_12_8_小结]
== 12.8 小结

本章介绍了轻量级流处理框架，包括它们的主要优点和折中点。它们是高度可伸缩的处理框架，重度依赖于与事件代理的集成来执行大规模数据处理。与 CMS 的高度集成为每个单独的微服务提供了可伸缩性。

与重量级框架相比，轻量级框架仍然是相对较新的技术。然而，它们提供的特性往往非常适合构建长期运行、独立且有状态的微服务，你需要探索这些特性值是否能用于你所负责的业务。
